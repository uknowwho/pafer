{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e419466-3d9a-47d4-8cea-71e9a5a66159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree._tree import TREE_LEAF\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79de6359-d22d-420f-abc5-649932d920c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The Adult data source: https://archive.ics.uci.edu/ml/datasets/adult\n",
    "adult_train = pd.read_csv(\"adult.data\", sep=',\\s+', engine='python')\n",
    "adult_test = pd.read_csv(\"adult.test\", sep=',\\s+', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b57d594f-dcc3-43e4-8427-63b3271f1014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt   education  education-num  \\\n",
       "0       39         State-gov   77516   Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311   Bachelors             13   \n",
       "2       38           Private  215646     HS-grad              9   \n",
       "3       53           Private  234721        11th              7   \n",
       "4       28           Private  338409   Bachelors             13   \n",
       "...    ...               ...     ...         ...            ...   \n",
       "32556   27           Private  257302  Assoc-acdm             12   \n",
       "32557   40           Private  154374     HS-grad              9   \n",
       "32558   58           Private  151910     HS-grad              9   \n",
       "32559   22           Private  201490     HS-grad              9   \n",
       "32560   52      Self-emp-inc  287927     HS-grad              9   \n",
       "\n",
       "           marital-status         occupation   relationship   race     sex  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "...                   ...                ...            ...    ...     ...   \n",
       "32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n",
       "32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
       "32558             Widowed       Adm-clerical      Unmarried  White  Female   \n",
       "32559       Never-married       Adm-clerical      Own-child  White    Male   \n",
       "32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country outcome  \n",
       "0              2174             0              40  United-States   <=50K  \n",
       "1                 0             0              13  United-States   <=50K  \n",
       "2                 0             0              40  United-States   <=50K  \n",
       "3                 0             0              40  United-States   <=50K  \n",
       "4                 0             0              40           Cuba   <=50K  \n",
       "...             ...           ...             ...            ...     ...  \n",
       "32556             0             0              38  United-States   <=50K  \n",
       "32557             0             0              40  United-States    >50K  \n",
       "32558             0             0              40  United-States   <=50K  \n",
       "32559             0             0              20  United-States   <=50K  \n",
       "32560         15024             0              40  United-States    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be8d298-5ce1-447f-9ba3-0354a0f435b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop incomplete instances, i.e. rows that contain ? values\n",
    "adult_test = adult_test[(adult_test != '?').all(1)]\n",
    "adult_train = adult_train[(adult_train != '?').all(1)]\n",
    "\n",
    "# drop fnlwgt column, which is uninformational and might cause overfitting\n",
    "adult_test = adult_test.drop(columns=[\"fnlwgt\"])\n",
    "adult_train = adult_train.drop(columns=[\"fnlwgt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca571d5-883d-42d0-a48e-67eab1517d18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# separate labels\n",
    "adult_test_y = adult_test['outcome']\n",
    "adult_test_X = adult_test.loc[:, adult_test.columns != 'outcome']\n",
    "adult_train_y = adult_train['outcome']\n",
    "adult_train_X = adult_train.loc[:, adult_train.columns != 'outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34458bef-a017-4086-bd7e-c3a78ceb8c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform labels to 0 and 1, above 50k is favorable outcome\n",
    "adult_test_y = adult_test_y.map({'<=50K.': 0, '>50K.': 1})\n",
    "adult_train_y = adult_train_y.map({'<=50K': 0, '>50K': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93bba5b1-b55f-4424-a697-416c444e041f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# separate sensitive attributes from model data\n",
    "adult_train_sex = adult_train_X[\"sex\"]\n",
    "adult_test_sex = adult_test_X[\"sex\"]\n",
    "adult_train_race = adult_train_X[\"race\"]\n",
    "adult_test_race = adult_test_X[\"race\"]\n",
    "adult_train_nc = adult_train_X[\"native-country\"]\n",
    "adult_test_nc = adult_test_X[\"native-country\"]\n",
    "adult_train_age = adult_train_X[\"age\"]\n",
    "adult_test_age = adult_test_X[\"age\"]\n",
    "adult_train_X = adult_train_X.drop(columns=[\"race\", \"sex\", \"native-country\", \"age\"])\n",
    "adult_test_X = adult_test_X.drop(columns=[\"race\", \"sex\", \"native-country\", \"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f258cfe4-e9c4-4323-979c-9ee04410a7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White        25933\n",
       "Non_White     4229\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert race data to binary white - non-white\n",
    "race_map_dict = {\"White\": \"White\", \"Black\": \"Non_White\", \"Asian-Pac-Islander\": \"Non_White\", \"Other\": \"Non_White\", \"Amer-Indian-Eskimo\": \"Non_White\"}\n",
    "adult_train_race = adult_train_race.map(race_map_dict)\n",
    "adult_test_race = adult_test_race.map(race_map_dict)\n",
    "adult_train_race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8805f52-94f7-41c3-9913-8470ec062b22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male-White          18038\n",
       "Female-White         7895\n",
       "Male-Non_White       2342\n",
       "Female-Non_White     1887\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the intersectional sensitive attributes into a dataframe and then into a series for the training set\n",
    "adult_train_sexrace = pd.concat([adult_train_sex, adult_train_race], axis=1)\n",
    "adult_train_sex_race = adult_train_sexrace[['sex', 'race']].agg('-'.join, axis=1)\n",
    "adult_train_sex_race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680366a4-179b-4173-916a-7befb2cba8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male-White          8982\n",
       "Female-White        3988\n",
       "Male-Non_White      1165\n",
       "Female-Non_White     925\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the two sensitive attributes into a dataframe and then into a series for the test set\n",
    "adult_test_sexrace = pd.concat([adult_test_sex, adult_test_race], axis=1)\n",
    "adult_test_sex_race = adult_test_sexrace[['sex', 'race']].agg('-'.join, axis=1)\n",
    "adult_test_sex_race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f28e1e2-dc8c-4570-90ae-52d3f3e69292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bin the numerical features into 5 equal-width bins\n",
    "bins = 5\n",
    "\n",
    "adult_train_X[\"education-cat\"] = pd.cut(adult_train_X[\"education-num\"], bins=bins)\n",
    "adult_train_X[\"capital-gain-cat\"] = pd.cut(adult_train_X[\"capital-gain\"], bins=bins)\n",
    "adult_train_X[\"capital-loss-cat\"] = pd.cut(adult_train_X[\"capital-loss\"], bins=bins)\n",
    "adult_train_X[\"hours-per-week-cat\"] = pd.cut(adult_train_X[\"hours-per-week\"], bins=bins)\n",
    "\n",
    "# use the same bins as the trainset to ensure we can predict later\n",
    "adult_test_X[\"education-cat\"] = pd.cut(adult_train_X[\"education-num\"], bins=bins)\n",
    "adult_test_X[\"capital-gain-cat\"] = pd.cut(adult_train_X[\"capital-gain\"], bins=bins)\n",
    "adult_test_X[\"capital-loss-cat\"] = pd.cut(adult_train_X[\"capital-loss\"], bins=bins)\n",
    "adult_test_X[\"hours-per-week-cat\"] = pd.cut(adult_train_X[\"hours-per-week\"], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73818f9b-4d5f-4441-803f-82b38eaaf615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>capital-loss-cat_(-4.356, 871.2]</th>\n",
       "      <th>capital-loss-cat_(871.2, 1742.4]</th>\n",
       "      <th>capital-loss-cat_(1742.4, 2613.6]</th>\n",
       "      <th>capital-loss-cat_(2613.6, 3484.8]</th>\n",
       "      <th>capital-loss-cat_(3484.8, 4356.0]</th>\n",
       "      <th>hours-per-week-cat_(0.902, 20.6]</th>\n",
       "      <th>hours-per-week-cat_(20.6, 40.2]</th>\n",
       "      <th>hours-per-week-cat_(40.2, 59.8]</th>\n",
       "      <th>hours-per-week-cat_(59.8, 79.4]</th>\n",
       "      <th>hours-per-week-cat_(79.4, 99.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                 13          2174             0              40   \n",
       "1                 13             0             0              13   \n",
       "2                  9             0             0              40   \n",
       "3                  7             0             0              40   \n",
       "4                 13             0             0              40   \n",
       "...              ...           ...           ...             ...   \n",
       "32556             12             0             0              38   \n",
       "32557              9             0             0              40   \n",
       "32558              9             0             0              40   \n",
       "32559              9             0             0              20   \n",
       "32560              9         15024             0              40   \n",
       "\n",
       "       workclass_Federal-gov  workclass_Local-gov  workclass_Private  \\\n",
       "0                          0                    0                  0   \n",
       "1                          0                    0                  0   \n",
       "2                          0                    0                  1   \n",
       "3                          0                    0                  1   \n",
       "4                          0                    0                  1   \n",
       "...                      ...                  ...                ...   \n",
       "32556                      0                    0                  1   \n",
       "32557                      0                    0                  1   \n",
       "32558                      0                    0                  1   \n",
       "32559                      0                    0                  1   \n",
       "32560                      0                    0                  0   \n",
       "\n",
       "       workclass_Self-emp-inc  workclass_Self-emp-not-inc  \\\n",
       "0                           0                           0   \n",
       "1                           0                           1   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "...                       ...                         ...   \n",
       "32556                       0                           0   \n",
       "32557                       0                           0   \n",
       "32558                       0                           0   \n",
       "32559                       0                           0   \n",
       "32560                       1                           0   \n",
       "\n",
       "       workclass_State-gov  ...  capital-loss-cat_(-4.356, 871.2]  \\\n",
       "0                        1  ...                                 1   \n",
       "1                        0  ...                                 1   \n",
       "2                        0  ...                                 1   \n",
       "3                        0  ...                                 1   \n",
       "4                        0  ...                                 1   \n",
       "...                    ...  ...                               ...   \n",
       "32556                    0  ...                                 1   \n",
       "32557                    0  ...                                 1   \n",
       "32558                    0  ...                                 1   \n",
       "32559                    0  ...                                 1   \n",
       "32560                    0  ...                                 1   \n",
       "\n",
       "       capital-loss-cat_(871.2, 1742.4]  capital-loss-cat_(1742.4, 2613.6]  \\\n",
       "0                                     0                                  0   \n",
       "1                                     0                                  0   \n",
       "2                                     0                                  0   \n",
       "3                                     0                                  0   \n",
       "4                                     0                                  0   \n",
       "...                                 ...                                ...   \n",
       "32556                                 0                                  0   \n",
       "32557                                 0                                  0   \n",
       "32558                                 0                                  0   \n",
       "32559                                 0                                  0   \n",
       "32560                                 0                                  0   \n",
       "\n",
       "       capital-loss-cat_(2613.6, 3484.8]  capital-loss-cat_(3484.8, 4356.0]  \\\n",
       "0                                      0                                  0   \n",
       "1                                      0                                  0   \n",
       "2                                      0                                  0   \n",
       "3                                      0                                  0   \n",
       "4                                      0                                  0   \n",
       "...                                  ...                                ...   \n",
       "32556                                  0                                  0   \n",
       "32557                                  0                                  0   \n",
       "32558                                  0                                  0   \n",
       "32559                                  0                                  0   \n",
       "32560                                  0                                  0   \n",
       "\n",
       "       hours-per-week-cat_(0.902, 20.6]  hours-per-week-cat_(20.6, 40.2]  \\\n",
       "0                                     0                                1   \n",
       "1                                     1                                0   \n",
       "2                                     0                                1   \n",
       "3                                     0                                1   \n",
       "4                                     0                                1   \n",
       "...                                 ...                              ...   \n",
       "32556                                 0                                1   \n",
       "32557                                 0                                1   \n",
       "32558                                 0                                1   \n",
       "32559                                 1                                0   \n",
       "32560                                 0                                1   \n",
       "\n",
       "       hours-per-week-cat_(40.2, 59.8]  hours-per-week-cat_(59.8, 79.4]  \\\n",
       "0                                    0                                0   \n",
       "1                                    0                                0   \n",
       "2                                    0                                0   \n",
       "3                                    0                                0   \n",
       "4                                    0                                0   \n",
       "...                                ...                              ...   \n",
       "32556                                0                                0   \n",
       "32557                                0                                0   \n",
       "32558                                0                                0   \n",
       "32559                                0                                0   \n",
       "32560                                0                                0   \n",
       "\n",
       "       hours-per-week-cat_(79.4, 99.0]  \n",
       "0                                    0  \n",
       "1                                    0  \n",
       "2                                    0  \n",
       "3                                    0  \n",
       "4                                    0  \n",
       "...                                ...  \n",
       "32556                                0  \n",
       "32557                                0  \n",
       "32558                                0  \n",
       "32559                                0  \n",
       "32560                                0  \n",
       "\n",
       "[30162 rows x 74 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert both datasets to one-hot encoding\n",
    "adult_train_cat_X = pd.get_dummies(adult_train_X)\n",
    "adult_test_cat_X = pd.get_dummies(adult_test_X)\n",
    "adult_train_cat_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11759c7e-548c-4a2b-9b59-7e8ed570af8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reindex all datasets\n",
    "adult_train_cat_X = adult_train_cat_X.reset_index(drop=True)\n",
    "adult_train_y = adult_train_y.reset_index(drop=True)\n",
    "adult_train_sex = adult_train_sex.reset_index(drop=True)\n",
    "adult_train_race = adult_train_race.reset_index(drop=True)\n",
    "adult_train_age = adult_train_age.reset_index(drop=True)\n",
    "adult_train_nc = adult_train_nc.reset_index(drop=True)\n",
    "adult_train_sex_race = adult_train_sex_race.reset_index(drop=True)\n",
    "\n",
    "adult_test_cat_X = adult_test_cat_X.reset_index(drop=True)\n",
    "adult_test_y = adult_test_y.reset_index(drop=True)\n",
    "adult_test_sex = adult_test_sex.reset_index(drop=True)\n",
    "adult_test_race = adult_test_race.reset_index(drop=True)\n",
    "adult_test_age = adult_test_age.reset_index(drop=True)\n",
    "adult_test_nc = adult_test_nc.reset_index(drop=True)\n",
    "adult_test_sex_race = adult_test_sex_race.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "036381f0-5e3f-46ca-b5f1-6198eaacf630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>capital-loss-cat_(-4.356, 871.2]</th>\n",
       "      <th>capital-loss-cat_(871.2, 1742.4]</th>\n",
       "      <th>capital-loss-cat_(1742.4, 2613.6]</th>\n",
       "      <th>capital-loss-cat_(2613.6, 3484.8]</th>\n",
       "      <th>capital-loss-cat_(3484.8, 4356.0]</th>\n",
       "      <th>hours-per-week-cat_(0.902, 20.6]</th>\n",
       "      <th>hours-per-week-cat_(20.6, 40.2]</th>\n",
       "      <th>hours-per-week-cat_(40.2, 59.8]</th>\n",
       "      <th>hours-per-week-cat_(59.8, 79.4]</th>\n",
       "      <th>hours-per-week-cat_(79.4, 99.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30157</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30158</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30159</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30160</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30161</th>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                 13          2174             0              40   \n",
       "1                 13             0             0              13   \n",
       "2                  9             0             0              40   \n",
       "3                  7             0             0              40   \n",
       "4                 13             0             0              40   \n",
       "...              ...           ...           ...             ...   \n",
       "30157             12             0             0              38   \n",
       "30158              9             0             0              40   \n",
       "30159              9             0             0              40   \n",
       "30160              9             0             0              20   \n",
       "30161              9         15024             0              40   \n",
       "\n",
       "       workclass_Federal-gov  workclass_Local-gov  workclass_Private  \\\n",
       "0                          0                    0                  0   \n",
       "1                          0                    0                  0   \n",
       "2                          0                    0                  1   \n",
       "3                          0                    0                  1   \n",
       "4                          0                    0                  1   \n",
       "...                      ...                  ...                ...   \n",
       "30157                      0                    0                  1   \n",
       "30158                      0                    0                  1   \n",
       "30159                      0                    0                  1   \n",
       "30160                      0                    0                  1   \n",
       "30161                      0                    0                  0   \n",
       "\n",
       "       workclass_Self-emp-inc  workclass_Self-emp-not-inc  \\\n",
       "0                           0                           0   \n",
       "1                           0                           1   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "...                       ...                         ...   \n",
       "30157                       0                           0   \n",
       "30158                       0                           0   \n",
       "30159                       0                           0   \n",
       "30160                       0                           0   \n",
       "30161                       1                           0   \n",
       "\n",
       "       workclass_State-gov  ...  capital-loss-cat_(-4.356, 871.2]  \\\n",
       "0                        1  ...                                 1   \n",
       "1                        0  ...                                 1   \n",
       "2                        0  ...                                 1   \n",
       "3                        0  ...                                 1   \n",
       "4                        0  ...                                 1   \n",
       "...                    ...  ...                               ...   \n",
       "30157                    0  ...                                 1   \n",
       "30158                    0  ...                                 1   \n",
       "30159                    0  ...                                 1   \n",
       "30160                    0  ...                                 1   \n",
       "30161                    0  ...                                 1   \n",
       "\n",
       "       capital-loss-cat_(871.2, 1742.4]  capital-loss-cat_(1742.4, 2613.6]  \\\n",
       "0                                     0                                  0   \n",
       "1                                     0                                  0   \n",
       "2                                     0                                  0   \n",
       "3                                     0                                  0   \n",
       "4                                     0                                  0   \n",
       "...                                 ...                                ...   \n",
       "30157                                 0                                  0   \n",
       "30158                                 0                                  0   \n",
       "30159                                 0                                  0   \n",
       "30160                                 0                                  0   \n",
       "30161                                 0                                  0   \n",
       "\n",
       "       capital-loss-cat_(2613.6, 3484.8]  capital-loss-cat_(3484.8, 4356.0]  \\\n",
       "0                                      0                                  0   \n",
       "1                                      0                                  0   \n",
       "2                                      0                                  0   \n",
       "3                                      0                                  0   \n",
       "4                                      0                                  0   \n",
       "...                                  ...                                ...   \n",
       "30157                                  0                                  0   \n",
       "30158                                  0                                  0   \n",
       "30159                                  0                                  0   \n",
       "30160                                  0                                  0   \n",
       "30161                                  0                                  0   \n",
       "\n",
       "       hours-per-week-cat_(0.902, 20.6]  hours-per-week-cat_(20.6, 40.2]  \\\n",
       "0                                     0                                1   \n",
       "1                                     1                                0   \n",
       "2                                     0                                1   \n",
       "3                                     0                                1   \n",
       "4                                     0                                1   \n",
       "...                                 ...                              ...   \n",
       "30157                                 0                                1   \n",
       "30158                                 0                                1   \n",
       "30159                                 0                                1   \n",
       "30160                                 1                                0   \n",
       "30161                                 0                                1   \n",
       "\n",
       "       hours-per-week-cat_(40.2, 59.8]  hours-per-week-cat_(59.8, 79.4]  \\\n",
       "0                                    0                                0   \n",
       "1                                    0                                0   \n",
       "2                                    0                                0   \n",
       "3                                    0                                0   \n",
       "4                                    0                                0   \n",
       "...                                ...                              ...   \n",
       "30157                                0                                0   \n",
       "30158                                0                                0   \n",
       "30159                                0                                0   \n",
       "30160                                0                                0   \n",
       "30161                                0                                0   \n",
       "\n",
       "       hours-per-week-cat_(79.4, 99.0]  \n",
       "0                                    0  \n",
       "1                                    0  \n",
       "2                                    0  \n",
       "3                                    0  \n",
       "4                                    0  \n",
       "...                                ...  \n",
       "30157                                0  \n",
       "30158                                0  \n",
       "30159                                0  \n",
       "30160                                0  \n",
       "30161                                0  \n",
       "\n",
       "[30162 rows x 74 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_train_cat_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f65cc-9f2e-424b-aa0b-04bac84f0f50",
   "metadata": {},
   "source": [
    "## PAFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d01a4c57-0a90-4f30-ac08-ccf3d533a83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def oracle(dataset, sens_dataset, rule, s_i, mechanism=None, epsilon=0.05, delta=0.001):\n",
    "    \"\"\"Returns some (differentially privatised) statistics on the sensitive attribute for the specified dataframe and rule.\n",
    "    \n",
    "    Args:\n",
    "        dataset: The DataFrame that the developers own, which does not contain sensitive attributes.\n",
    "            Used to calculate total quantities in (root) nodes.\n",
    "        sens_dataset: A Series that the developers do not own, which contains the sensitive attributes. \n",
    "            Combined sensitive attributes should be encoded as a Series, e.g. Black-Female\n",
    "        rule: The rule for which the to estimate the sensitive attribute. \n",
    "            rule must be a pandas conditional expression as a string, e.g. \"(adult_test_cat_X['marital-status_Married-civ-spouse']<= 0.5)\"\n",
    "        s_i: The sensitive attribute, its name comes from the ith element in the set S of sensitive attributes.\n",
    "            s_i should thus be in sens_dataset. \n",
    "        mechanism: The privacy mechanism used on the returned counts. Can be one of \"gaussian\", \"laplacian\", \"exponential\", None. \n",
    "        epsilon: The privacy budget. Should be larger than 0.\n",
    "        delta: The privacy margin. Ignored when mechanism is either laplacian or gaussian. Should be in (0, 1]. \n",
    "        \n",
    "    Returns:\n",
    "        The number of times s_i occurs in sens_dataset, potentially privatised via the mechanism. \n",
    "        \"\"\"\n",
    "        \n",
    "    # check epsilon and delta parameters\n",
    "    if epsilon <= 0 or (mechanism == \"gaussian\" and (delta <= 0 or delta > 1 or epsilon > 1)):\n",
    "        raise ValueError(\"The value of delta should be in (0,1] when using the gaussian mechanism\")\n",
    "    \n",
    "    if not sens_dataset.isin([s_i]).any():\n",
    "        raise KeyError(\"The requested sensitive attribute (s_i) is not in the sensitive dataframe (sens_dataset)\")\n",
    "        \n",
    "    # the answer if no privacy mechanism is applied\n",
    "    try:\n",
    "        # engine might differ for your version, i.e. engine=\"pandas\"\n",
    "        no_mechanism = sens_dataset.loc[dataset[pd.eval(rule, engine='python')].index].value_counts(sort=False)[s_i]\n",
    "        \n",
    "    except KeyError:\n",
    "        no_mechanism = 0\n",
    "    \n",
    "    if mechanism == \"laplacian\":\n",
    "        # this is a histogram query so the l1-sensitivity = 1 as per Dwork & Roth \n",
    "        sensitivity = 1\n",
    "        return no_mechanism + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "    \n",
    "    elif mechanism == \"gaussian\":\n",
    "        # this is a histogram query so the l2-sensitivity = 2 as per Dwork & Roth\n",
    "        sensitivity = 2\n",
    "        return no_mechanism + np.random.normal(loc=0, scale=2 * sensitivity**2 * np.log(1.25 / delta) / epsilon**2)\n",
    "    \n",
    "    elif mechanism == \"exponential\":\n",
    "        # this query can only change by 1 if an instance is omitted so l1-sensitivity = 1\n",
    "        sensitivity = 1\n",
    "        \n",
    "        # np.arange is [start, stop) so + 1 for entire possible range\n",
    "        possible_values = np.arange(0, sens_dataset.loc[dataset[pd.eval(rule, engine='python')].index].value_counts().to_numpy().sum() + 1)\n",
    "        \n",
    "        # the utility is higher when the value is closer to the actual value\n",
    "        utility_scores = np.array([no_mechanism - abs(no_mechanism - value) for value in possible_values]) / 100\n",
    "        probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in utility_scores]\n",
    "        \n",
    "        # normalize probabilties to sum to 1\n",
    "        probabilities /= np.linalg.norm(probabilities, ord=1)\n",
    "        return np.random.choice(possible_values, p=probabilities)\n",
    "\n",
    "    # if no mechanism is given, return the unprivatised cocunt\n",
    "    return no_mechanism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "393dda03-116a-4dd2-b11c-030ab0a36836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def statistical_parity(y_pred, sens_dataset):\n",
    "    \"\"\"Calculates Statistical Parity Ratio using the predictions and the actual sensitive feature values. \n",
    "    \n",
    "    Args:\n",
    "        y_pred: The predictions, should be of same size as sens_dataset.\n",
    "        sens_dataset: The Series with the sensitive attributes.\n",
    "        \n",
    "    Returns:\n",
    "        The true statistical parity ratio.\n",
    "        \"\"\"\n",
    "    accept_rates = []\n",
    "    \n",
    "    for sens_attr in sorted(sens_dataset.unique()):\n",
    "        accept_rates.append(np.sum((sens_dataset == sens_attr) & y_pred) / np.sum(sens_dataset == sens_attr))\n",
    "        \n",
    "    return min(accept_rates) / max(accept_rates)\n",
    "\n",
    "\n",
    "def estimate_sp(pos_ruleset, dataset, sens_dataset, S, mechanism, epsilon, delta=0.001):\n",
    "    \"\"\"Returns the estimated Statistical Parity of a tree for a privacy mechanism. The PAFER algorithm. \n",
    "    \n",
    "    Args:\n",
    "        pos_ruleset: A list of rules that classify favorably in the tree. This is the representation of the\n",
    "        (relevant parts of the) tree. \n",
    "        dataset: The DataFrame that the developers own that does not contain sensitive feature values.\n",
    "        sens_dataset: The Series that contains the sensitive features, which the developers do not own.\n",
    "        S: The set/list of sensitive attributes, should all be in the sens_dataset attribute.\n",
    "        mechanism: The mechanism with which to privatise the query answers. \n",
    "        epsilon: The privacy budget for the privacy mechanism. Should be larger than 0.\n",
    "        delta: The privacy margin. Ignored when mechanism is either laplacian or gaussian. Should be in (0, 1].\n",
    "        \n",
    "    Returns:\n",
    "        The statistical parity ratio for the specified pos_ruleset. \n",
    "        \"\"\"\n",
    "    \n",
    "    poscounts_per_si = np.zeros(len(S))\n",
    "    \n",
    "    # the variable name of the current dataset is inferred from the ruleset\n",
    "    datasetname = str(pos_ruleset[0].split('[')[0])[1:]\n",
    "    \n",
    "    # the base rule is a rule that includes all individuals, i.e. the condition is a tautology\n",
    "    # in this case we select all rows that have a value that is in the set of possible values of the first column\n",
    "    base_rule = f\"({datasetname}[{datasetname}.columns[0]].isin({datasetname}[{datasetname}.columns[0]].unique()))\"\n",
    "    \n",
    "    # query the size of each sensitive attribute in the dataset\n",
    "    total_per_si = [oracle(dataset, sens_dataset, base_rule, s_i, mechanism, 0.5 * epsilon, delta) for s_i in S]\n",
    "    \n",
    "    # replace each invalid value with balanced totals\n",
    "    for i, tot in enumerate(total_per_si):\n",
    "        if tot < 0 or tot > len(sens_dataset):\n",
    "            total_per_si[i] = (1 / len(S)) * len(sens_dataset)\n",
    "        \n",
    "    total_per_si = np.array(total_per_si)\n",
    "    \n",
    "    for rule in pos_ruleset:\n",
    "        # for each rule we find the distribution of sensitive attributes\n",
    "        rule_counts = np.zeros(len(S))\n",
    "        rule_total = len(sens_dataset[pd.eval(rule)])\n",
    "        \n",
    "        for i, s_i in enumerate(S):\n",
    "            # because the queries are disjoint, epsilon remains equal across queries\n",
    "            answer = round(oracle(dataset, sens_dataset, rule, s_i, mechanism, 0.5 * epsilon, delta))\n",
    "\n",
    "            # if invalid answers from query: replace with balanced node value\n",
    "            if answer < 0 or answer > len(sens_dataset):\n",
    "                answer = (1 / len(S)) * rule_total\n",
    "\n",
    "            rule_counts[i] += answer\n",
    "        \n",
    "        # the distribution for the current rule is added to the total\n",
    "        poscounts_per_si += rule_counts\n",
    "    \n",
    "    # calculate and return sp\n",
    "    accept_rates = poscounts_per_si / total_per_si\n",
    "    return np.min(accept_rates) / np.max(accept_rates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712302fb-f570-47fe-8680-0af8bbf5bc37",
   "metadata": {},
   "source": [
    "## Tree construction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3171e940-85e0-4479-bd42-023722256e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_best_tree(dataset, dataset_labels, minleaf=1, ccp_alpha=0.01):\n",
    "    \"\"\"Train a tree for balanced accuracy performance using grid search. \n",
    "    \n",
    "    dataset: The training data (without sensitive attributes!).\n",
    "    dataset_labels: The true outcomes for the prediction task.\n",
    "    minleaf: The tree construction parameter denoting the minimum number of instances in a leaf node.\n",
    "        minleaf should be in (0, 1]. \n",
    "        \n",
    "    Returns: \n",
    "        The best performing decision tree.\"\"\"\n",
    "    \n",
    "    # no random_state because we want a different tree each run\n",
    "    tree = DecisionTreeClassifier()\n",
    "\n",
    "    parameter_grid = {\"criterion\":[\"entropy\", \"gini\"],\n",
    "                      \"max_features\":[\"sqrt\", \"log2\"], \n",
    "                      \"min_samples_leaf\":[minleaf], \"ccp_alpha\": [ccp_alpha]}\n",
    "    \n",
    "    # train and return the best tree\n",
    "    tree_cv = GridSearchCV(tree, param_grid=parameter_grid, scoring='balanced_accuracy', n_jobs=2, cv=3, verbose=0)\n",
    "    tree_cv.fit(dataset, dataset_labels)\n",
    "    best_tree = tree_cv.best_estimator_\n",
    "    return best_tree\n",
    "\n",
    "best_tree = find_best_tree(adult_train_cat_X, adult_train_y, ccp_alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae2d046-3866-461a-9d2e-585ff3a019ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# taken from: https://stackoverflow.com/a/51398390\n",
    "def is_leaf(inner_tree, index):\n",
    "    # check whether node is leaf node\n",
    "    return (inner_tree.children_left[index] == TREE_LEAF and \n",
    "            inner_tree.children_right[index] == TREE_LEAF)\n",
    "\n",
    "def prune_index(inner_tree, decisions, index=0):\n",
    "    # start pruning from the bottom - if we start from the top, we might miss\n",
    "    # nodes that become leaves during pruning\n",
    "    if not is_leaf(inner_tree, inner_tree.children_left[index]):\n",
    "        prune_index(inner_tree, decisions, inner_tree.children_left[index])\n",
    "    if not is_leaf(inner_tree, inner_tree.children_right[index]):\n",
    "        prune_index(inner_tree, decisions, inner_tree.children_right[index])\n",
    "\n",
    "    # prune children if both children are leaves now and make the same decision\n",
    "    if (is_leaf(inner_tree, inner_tree.children_left[index]) and\n",
    "        is_leaf(inner_tree, inner_tree.children_right[index]) and\n",
    "        (decisions[index] == decisions[inner_tree.children_left[index]]) and \n",
    "        (decisions[index] == decisions[inner_tree.children_right[index]])):\n",
    "        # turn node into a leaf by \"unlinking\" its children\n",
    "        inner_tree.children_left[index] = TREE_LEAF\n",
    "        inner_tree.children_right[index] = TREE_LEAF\n",
    "\n",
    "def prune_duplicate_leaves(mdl):\n",
    "    # Remove leaves if all siblings make the same decision\n",
    "    decisions = mdl.tree_.value.argmax(axis=2).flatten().tolist() # Decision for each node\n",
    "    prune_index(mdl.tree_, decisions)\n",
    "    \n",
    "# pruning happens in-place\n",
    "prune_duplicate_leaves(best_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69df189d-8a53-4288-965a-8fd91df7d716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positive_rules (tree, rules):\n",
    "    \"\"\"From the extracted rules, return those that have a favorable classification. \n",
    "\n",
    "    Arg:\n",
    "        tree: The tree classification object from which the rules are extracted. \n",
    "        rules: Dict of which the values are rule strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of all the rules that classify favorably\"\"\"\n",
    "\n",
    "    # only those rules are added for which the majority of individuals in the node is at index 1, i.e. max\n",
    "    # index 1 corresponds to class 1 which we ensured was the favorable outcome\n",
    "    return [rule for node_id, rule in rules.items() if np.argmax(tree.tree_.value[node_id][0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2fd1833-51a4-4365-b682-485fda54d592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taken from: https://stackoverflow.com/a/56427596\n",
    "def extract_pos_rules(tree, dataset, datasetname):\n",
    "    n_nodes = tree.tree_.node_count\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    feature = tree.tree_.feature\n",
    "    threshold = tree.tree_.threshold\n",
    "\n",
    "    def find_path(node_numb, path, x):\n",
    "        path.append(node_numb)\n",
    "        if node_numb == x:\n",
    "            return True\n",
    "        left = False\n",
    "        right = False\n",
    "        if (children_left[node_numb] !=-1):\n",
    "            left = find_path(children_left[node_numb], path, x)\n",
    "        if (children_right[node_numb] !=-1):\n",
    "            right = find_path(children_right[node_numb], path, x)\n",
    "        if left or right :\n",
    "            return True\n",
    "        path.remove(node_numb)\n",
    "        return False\n",
    "\n",
    "\n",
    "    def get_rule(datasetname, path, column_names):\n",
    "        mask = '('\n",
    "        for index, node in enumerate(path):\n",
    "            # check if we are not in the leaf\n",
    "            if index!=len(path)-1:\n",
    "                # under or over the threshold?\n",
    "                if (children_left[node] == path[index+1]):\n",
    "                    mask += f\"{datasetname}['{column_names[feature[node]]}']<= {threshold[node]}\\t \"\n",
    "                else:\n",
    "                    mask += f\"{datasetname}['{column_names[feature[node]]}']> {threshold[node]} \\t \"\n",
    "\n",
    "        # insert the & at the right places\n",
    "        mask = mask.replace(\"\\t\", \"&\", mask.count(\"\\t\") - 1)\n",
    "        mask = mask.replace(\"\\t\", \"\")\n",
    "        mask += \")\"\n",
    "        return mask\n",
    "    \n",
    "    # Leaves\n",
    "    leave_id = tree.apply(dataset)\n",
    "\n",
    "    paths = {}\n",
    "    for leaf in np.unique(leave_id):\n",
    "        path_leaf = []\n",
    "        find_path(0, path_leaf, leaf)\n",
    "        paths[leaf] = np.unique(np.sort(path_leaf))\n",
    "\n",
    "    rules = {}\n",
    "    for key in paths:\n",
    "        rules[key] = get_rule(datasetname, paths[key], [name for name in dataset.columns])\n",
    "        \n",
    "    return positive_rules(tree, rules)\n",
    "        \n",
    "extract_pos_rules(best_tree, adult_train_cat_X, \"adult_train_cat_X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb331240-0d5a-436b-9a4a-e53bd787eee6",
   "metadata": {},
   "source": [
    "## PAFER Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13e3efde-21e1-436a-b1ee-5225295c00fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bootstrap(dataset, dataset_labels, sens_dataset):\n",
    "    \"\"\"A bootstrapping function that helps to diversify the tree generating process.\"\"\"\n",
    "    indices = np.random.choice(dataset.index, size=len(dataset.index))\n",
    "    \n",
    "    return dataset.iloc[indices], dataset_labels.iloc[indices], sens_dataset.iloc[indices]\n",
    "\n",
    "# dataset, labels, sens_dataset = bootstrap(adult_test_cat_X, adult_test_y, adult_test_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08e50207-9969-4a34-b6ec-dcf843623d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(trainset, sens_trainset, trainsetname, trainset_labels, testset, sens_testset, testsetname, \n",
    "               testset_labels, epsilons=[0.05, 0.1, 0.15, 0.2, 0.25], minleaf=1, ccp_alpha=0.0, runs=5, combined=False):\n",
    "    \"\"\"Performs an experiment as described in the paper.\n",
    "    \n",
    "    trainset: The DataFrame containing the training instances.\n",
    "    sens_trainset: The Series containing the sensitive attribute values for the trainset.\n",
    "    trainsetname: The variable name of the trainset. Required because of rule evaluation.\n",
    "    trainset_labels: The true outcomes for the prediction task for the trainset.\n",
    "    testset: The DataFrame containing the test instances.\n",
    "    sens_testset: The Series containing the sensitive attribute values for the testset.\n",
    "    testsetname: The variable name of the testset. Required because of rule evaluation.\n",
    "    testset_labels: The true outcomes for the prediction task for the testset.\n",
    "    epsilons: The different privacy budgets to try. \n",
    "        epsilons must be a list.\n",
    "    minleaf: The tree construction parameter denoting the minimum number of instances in a leaf node.\n",
    "        minleaf should be in (0, 1].\n",
    "    runs: The number of runs to average over. Advised to be quite high (e.g. 50) to compensate for noise.\n",
    "    combined: Whether to combine all positive rules into one query. \n",
    "    \n",
    "    Returns:\n",
    "        The true SP of the tree and the estimated SP.\"\"\"\n",
    "    \n",
    "    \n",
    "    tree_sps = np.zeros((runs, len(epsilons)))\n",
    "    tree_depths = np.zeros((runs, len(epsilons)))\n",
    "    estimated_sps = np.zeros((runs, len(epsilons)))\n",
    "    for i in range(runs):\n",
    "        ruleset = []\n",
    "        \n",
    "        # keep boostrapping until we find a ruleset that has at least one positive rule\n",
    "        while ruleset == [] or ruleset == ['()']:\n",
    "            # sample with replacement\n",
    "            dataset, dataset_labels, sens_dataset = bootstrap(trainset, trainset_labels, sens_trainset)\n",
    "            \n",
    "            # build tree \n",
    "            best_tree = find_best_tree(trainset, trainset_labels, minleaf, ccp_alpha)\n",
    "        \n",
    "            # extract positive rules\n",
    "            prune_duplicate_leaves(best_tree)\n",
    "            ruleset = extract_pos_rules(best_tree, trainset, testsetname)\n",
    "        \n",
    "        if combined:\n",
    "            ruleset = [\" | \".join(rule for rule in ruleset)]\n",
    "\n",
    "        # calculate true SP\n",
    "        tree_sps[i] = statistical_parity(best_tree.predict(testset), sens_testset)\n",
    "        tree_depths[i] = best_tree.tree_.max_depth\n",
    "        \n",
    "        # apply PAFER\n",
    "        for j, epsilon in enumerate(epsilons):\n",
    "            estimated_sps[i, j] = estimate_sp(ruleset, testset, sens_testset, sorted(sens_testset.unique()), mechanism='laplacian', epsilon=epsilon)\n",
    "        \n",
    "    return tree_sps, tree_depths, estimated_sps\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d601d306-d9e6-409b-8d1a-8f3d0c4ad4d6",
   "metadata": {},
   "source": [
    "## MINLEAF EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58372d-00f0-4203-bad6-d39071ab0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to run the experiments\n",
    "# TODO: current datastructures are not optimal or intuitive so could be helpful to streamline (for plotting)\n",
    "minleafs = np.linspace(0.2, 0.001, 80)\n",
    "runs = 50\n",
    "\n",
    "# storage for results\n",
    "tree_sps = []\n",
    "tree_depths = []\n",
    "estimated_sps = []\n",
    "for minleaf in tqdm(minleafs):\n",
    "    t_sps, t_depths, e_sps = experiment(adult_train_cat_X, adult_train_sex, \"adult_train_cat_X\", adult_train_y, \n",
    "                                         adult_test_cat_X, adult_test_sex, \"adult_test_cat_X\", adult_test_y, minleaf=minleaf, runs=runs)\n",
    "    \n",
    "    tree_sps.append(t_sps)\n",
    "    tree_depths.append(t_depths)\n",
    "    estimated_sps.append(e_sps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403595d7-604a-4d07-b594-79b5e11fb81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_sps = np.array(tree_sps)\n",
    "tree_depths = np.array(tree_depths)\n",
    "estimated_sps = np.array(estimated_sps)\n",
    "\n",
    "for arr, name in zip([tree_sps, tree_depths, estimated_sps], [\"tree_sps\", \"tree_depths\", \"estimated_sps\"]):\n",
    "    with open(f\"adult-sex-minleaf-{name}\", \"wb\") as f:\n",
    "        np.save(f, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb39ea3-46cc-4f21-85ed-4c71c4ef5df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "minleafs = np.linspace(0.2, 0.001, 80)\n",
    "runs = 50\n",
    "\n",
    "# storage for results\n",
    "tree_sps = []\n",
    "tree_depths = []\n",
    "estimated_sps = []\n",
    "for minleaf in tqdm(minleafs):\n",
    "    t_sps, t_depths, e_sps = experiment(adult_train_cat_X, adult_train_race, \"adult_train_cat_X\", adult_train_y, \n",
    "                                         adult_test_cat_X, adult_test_race, \"adult_test_cat_X\", adult_test_y, minleaf=minleaf, runs=runs)\n",
    "    \n",
    "    tree_sps.append(t_sps)\n",
    "    tree_depths.append(t_depths)\n",
    "    estimated_sps.append(e_sps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a155652-ebd6-4dc3-8892-e2b206d7dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_sps = np.array(tree_sps)\n",
    "tree_depths = np.array(tree_depths)\n",
    "estimated_sps = np.array(estimated_sps)\n",
    "\n",
    "for arr, name in zip([tree_sps, tree_depths, estimated_sps], [\"tree_sps\", \"tree_depths\", \"estimated_sps\"]):\n",
    "    with open(f\"adult-race-minleaf-{name}\", \"wb\") as f:\n",
    "        np.save(f, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155a18b-9169-4268-aa61-bde3d71a21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "minleafs = np.linspace(0.2, 0.001, 80)\n",
    "runs = 50\n",
    "\n",
    "# storage for results\n",
    "tree_sps = []\n",
    "tree_depths = []\n",
    "estimated_sps = []\n",
    "for minleaf in tqdm(minleafs):\n",
    "    t_sps, t_depths, e_sps = experiment(adult_train_cat_X, adult_train_sex_race, \"adult_train_cat_X\", adult_train_y, \n",
    "                                         adult_test_cat_X, adult_test_sex_race, \"adult_test_cat_X\", adult_test_y, minleaf=minleaf, runs=runs)\n",
    "    \n",
    "    tree_sps.append(t_sps)\n",
    "    tree_depths.append(t_depths)\n",
    "    estimated_sps.append(e_sps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731ce75-11d9-4b5f-a452-ca3db52c242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_sps = np.array(tree_sps)\n",
    "tree_depths = np.array(tree_depths)\n",
    "estimated_sps = np.array(estimated_sps)\n",
    "\n",
    "for arr, name in zip([tree_sps, tree_depths, estimated_sps], [\"tree_sps\", \"tree_depths\", \"estimated_sps\"]):\n",
    "    with open(f\"adult-sex_race-minleaf-{name}\", \"wb\") as f:\n",
    "        np.save(f, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a17190-0248-4fcb-bfbf-cc22167e3534",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CCP_ALPHA EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0531ec9c-80b3-4156-9fb9-968e6011362e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [18:04<00:00, 108.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# script to run the experiments\n",
    "ccp_alphas = np.linspace(0.05, 0.001, 80)\n",
    "runs = 50\n",
    "\n",
    "# storage for results\n",
    "tree_sps = []\n",
    "tree_depths = []\n",
    "estimated_sps = []\n",
    "for ccp_alpha in tqdm(ccp_alphas):\n",
    "    t_sps, t_depths, e_sps = experiment(adult_train_cat_X, adult_train_sex, \"adult_train_cat_X\", adult_train_y, \n",
    "                                         adult_test_cat_X, adult_test_sex, \"adult_test_cat_X\", adult_test_y, ccp_alpha=ccp_alpha, runs=runs)\n",
    "    \n",
    "    tree_sps.append(t_sps)\n",
    "    tree_depths.append(t_depths)\n",
    "    estimated_sps.append(e_sps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0fa331d9-5e2d-4760-b3f2-d94e44d0fd48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree_sps = np.array(tree_sps)\n",
    "estimated_sps = np.array(estimated_sps)\n",
    "tree_depths = np.array(tree_depths)\n",
    "\n",
    "for arr, name in zip([tree_sps, tree_depths, estimated_sps], [\"tree_sps\", \"tree_depths\" \"estimated_sps\"]):\n",
    "    with open(f\"adult-sex-ccp-{name}\", \"wb\") as f:\n",
    "        np.save(f, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ce467-bf36-44e9-9c2d-5956888e92ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccp_alphas = np.linspace(0.05, 0.001, 80)\n",
    "runs = 50\n",
    "\n",
    "# storage for results\n",
    "tree_sps = []\n",
    "tree_depths = []\n",
    "estimated_sps = []\n",
    "for ccp_alpha in tqdm(ccp_alphas):\n",
    "    t_sps, t_depths e_sps = experiment(adult_train_cat_X, adult_train_race, \"adult_train_cat_X\", adult_train_y, \n",
    "                                         adult_test_cat_X, adult_test_race, \"adult_test_cat_X\", adult_test_y, ccp_alpha=ccp_alpha, runs=runs)\n",
    "    \n",
    "    tree_sps.append(t_sps)\n",
    "    tree_depths.append(t_depths)\n",
    "    estimated_sps.append(e_sps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e5524232-99cd-4053-b8ee-2b1a03a15cff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree_sps = np.array(tree_sps)\n",
    "estimated_sps = np.array(estimated_sps)\n",
    "tree_depths = np.array(tree_depths)\n",
    "\n",
    "for arr, name in zip([tree_sps, tree_depths, estimated_sps], [\"tree_sps\", \"tree_depths\", \"estimated_sps\"]):\n",
    "    with open(f\"adult-race-ccp-{name}\", \"wb\") as f:\n",
    "        np.save(f, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bdfef-37ef-4c04-9a6d-25b44273547e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccp_alphas = np.linspace(0.05, 0.001, 80)\n",
    "runs = 50\n",
    "\n",
    "# storage for results\n",
    "tree_sps = []\n",
    "tree_depths = []\n",
    "estimated_sps = []\n",
    "for ccp_alpha in tqdm(ccp_alphas):\n",
    "    t_sps, t_depths, e_sps = experiment(adult_train_cat_X, adult_train_sex_race, \"adult_train_cat_X\", adult_train_y, \n",
    "                                         adult_test_cat_X, adult_test_sex_race, \"adult_test_cat_X\", adult_test_y, ccp_alpha=ccp_alpha, runs=runs)\n",
    "    \n",
    "    tree_sps.append(t_sps)\n",
    "    tree_depths.append(t_depths)\n",
    "    estimated_sps.append(e_sps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7692c8ea-7826-46d7-9d56-6f5d3a46558b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree_sps = np.array(tree_sps)\n",
    "estimated_sps = np.array(estimated_sps)\n",
    "tree_depths = np.array(tree_depths)\n",
    "\n",
    "for arr, name in zip([tree_sps, tree_depths, estimated_sps], [\"tree_sps\", \"tree_depths\", \"estimated_sps\"]):\n",
    "    with open(f\"adult-sex_race-ccp-{name}\", \"wb\") as f:\n",
    "        np.save(f, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea6dffd-c285-45e1-bed6-6731e401277e",
   "metadata": {},
   "source": [
    "## Preliminary Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b6f49c-4d7d-4c48-9a68-b621d88ad236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minleafs = np.linspace(0.2, 0.001, 80)\n",
    "# runs = 50\n",
    "\n",
    "# # storage for results\n",
    "# tree_sps = []\n",
    "# estimated_sps = []\n",
    "# for minleaf in tqdm(minleafs):\n",
    "#     t_sps, e_sps = experiment(adult_train_cat_X, adult_train_race, \"adult_train_cat_X\", adult_train_y, \n",
    "#                                          adult_test_cat_X, adult_test_race, \"adult_test_cat_X\", adult_test_y, minleaf=minleaf, runs=runs)\n",
    "    \n",
    "#     tree_sps.append(t_sps)\n",
    "#     estimated_sps.append(e_sps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d59edfed-f17a-4529-a5c0-c7eff4900ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tree_sps = np.array(tree_sps)\n",
    "# estimated_sps = np.array(estimated_sps)\n",
    "\n",
    "# for arr, name in zip([tree_sps, estimated_sps], [\"tree_sps\", \"estimated_sps\"]):\n",
    "#     with open(f\"adult-race-{name}-prelim\", \"wb\") as f:\n",
    "#         np.save(f, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6d7b6e9-fde0-41d9-a9b7-30eebb0ed63a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.56158666, 0.67429807, 0.62729312, 0.63788161, 0.6258125 ],\n",
       "        [0.68767384, 0.75624062, 0.69611309, 0.6905098 , 0.69287197],\n",
       "        [0.59128158, 0.58010349, 0.68337842, 0.64348167, 0.58882402],\n",
       "        [0.56643611, 0.61609449, 0.58226534, 0.64314025, 0.65472144],\n",
       "        [0.5695656 , 0.71448554, 0.63400735, 0.63285944, 0.63195388],\n",
       "        [0.67738089, 0.59323878, 0.64393849, 0.68199716, 0.61076666],\n",
       "        [0.70573709, 0.62834749, 0.61471532, 0.62465847, 0.62974223],\n",
       "        [0.63612126, 0.65199927, 0.66953198, 0.69131622, 0.67930011],\n",
       "        [0.62331176, 0.64760974, 0.68038415, 0.70384549, 0.67939058],\n",
       "        [0.63037357, 0.62012692, 0.58502845, 0.62239223, 0.63153792],\n",
       "        [0.7181779 , 0.617675  , 0.64051758, 0.59238577, 0.59617007],\n",
       "        [0.64629109, 0.64611606, 0.69280751, 0.68660065, 0.69228723],\n",
       "        [0.64704817, 0.69047115, 0.61983063, 0.56585228, 0.68647668],\n",
       "        [0.68014494, 0.6878075 , 0.65954098, 0.66484317, 0.63556792],\n",
       "        [0.5848538 , 0.64338251, 0.66134357, 0.65654949, 0.63060375],\n",
       "        [0.82450131, 0.62808813, 0.63027099, 0.64703454, 0.62029221],\n",
       "        [0.4675582 , 0.53452386, 0.66628132, 0.57530286, 0.61647938],\n",
       "        [0.54441541, 0.6963186 , 0.72748234, 0.69606404, 0.69875205],\n",
       "        [0.67244942, 0.67521667, 0.71249546, 0.67623706, 0.68351454],\n",
       "        [0.48168094, 0.64987924, 0.64152415, 0.56943276, 0.65622267],\n",
       "        [0.70818383, 0.61356778, 0.53000486, 0.60518866, 0.61504162],\n",
       "        [0.66324742, 0.65948921, 0.68090839, 0.62261746, 0.63624599],\n",
       "        [0.71299883, 0.6904425 , 0.6892988 , 0.69886224, 0.69527849],\n",
       "        [0.44887229, 0.59899143, 0.64955263, 0.63014326, 0.64626301],\n",
       "        [0.5783114 , 0.56912915, 0.63164859, 0.64253213, 0.63193581]],\n",
       "\n",
       "       [[0.71872304, 0.67374268, 0.70070353, 0.67409369, 0.70336477],\n",
       "        [0.59175879, 0.67498065, 0.67655147, 0.69983102, 0.72769782],\n",
       "        [0.63952384, 0.68297669, 0.70322611, 0.69205016, 0.67653253],\n",
       "        [0.62945519, 0.66458444, 0.68252626, 0.63429338, 0.67343622],\n",
       "        [0.63773467, 0.71612565, 0.69281677, 0.65614576, 0.66956005],\n",
       "        [0.69710704, 0.66571573, 0.6711162 , 0.67431949, 0.69059633],\n",
       "        [0.60809424, 0.68797672, 0.70260442, 0.68849192, 0.69060945],\n",
       "        [0.69345358, 0.68023984, 0.69239022, 0.68301929, 0.68740917],\n",
       "        [0.66977017, 0.79025114, 0.70097588, 0.67697807, 0.64629667],\n",
       "        [0.6786989 , 0.67780467, 0.6956935 , 0.68942119, 0.68936409],\n",
       "        [0.67437743, 0.68678533, 0.67474024, 0.69097297, 0.6497938 ],\n",
       "        [0.68297504, 0.70540754, 0.67219728, 0.67719359, 0.68529295],\n",
       "        [0.62016541, 0.66720019, 0.69412851, 0.67247275, 0.69590493],\n",
       "        [0.77435641, 0.6705208 , 0.62910915, 0.67164643, 0.69589483],\n",
       "        [0.68861201, 0.60950158, 0.67524547, 0.72277206, 0.69554357],\n",
       "        [0.68912464, 0.59954574, 0.68316063, 0.69148733, 0.68452196],\n",
       "        [0.59553208, 0.67976906, 0.80573878, 0.69118584, 0.68476884],\n",
       "        [0.63822122, 0.63770663, 0.68181128, 0.69199388, 0.69748674],\n",
       "        [0.65188133, 0.72523467, 0.69061794, 0.67764913, 0.70150646],\n",
       "        [0.73908075, 0.75565826, 0.68875751, 0.68102687, 0.68243621],\n",
       "        [0.72214289, 0.74514349, 0.65991667, 0.71575511, 0.7086752 ],\n",
       "        [0.65936347, 0.68083937, 0.67244478, 0.73678107, 0.65711738],\n",
       "        [0.77720519, 0.6960616 , 0.69565046, 0.66717669, 0.69405568],\n",
       "        [0.61864004, 0.68988842, 0.72687764, 0.68553914, 0.68205867],\n",
       "        [0.87044512, 0.67415555, 0.72265571, 0.7059977 , 0.67977725]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimated_sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223fd244-4199-4187-bb49-4313ac7166ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
