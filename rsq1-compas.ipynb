{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853d76de-66f0-4685-ac8f-e13c4eddb864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.tree._tree import TREE_LEAF\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, balanced_accuracy_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import ttest_ind\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f279bcd4-fe8c-43fa-b633-4e949bc6ab57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>10996</td>\n",
       "      <td>steven butler</td>\n",
       "      <td>steven</td>\n",
       "      <td>butler</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>Male</td>\n",
       "      <td>1992-07-17</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>2013-11-22</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>10997</td>\n",
       "      <td>malcolm simmons</td>\n",
       "      <td>malcolm</td>\n",
       "      <td>simmons</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-03-25</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>2014-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>10999</td>\n",
       "      <td>winston gregory</td>\n",
       "      <td>winston</td>\n",
       "      <td>gregory</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1958-10-01</td>\n",
       "      <td>57</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>2014-01-13</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>11000</td>\n",
       "      <td>farrah jean</td>\n",
       "      <td>farrah</td>\n",
       "      <td>jean</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>Female</td>\n",
       "      <td>1982-11-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>11001</td>\n",
       "      <td>florencia sanmartin</td>\n",
       "      <td>florencia</td>\n",
       "      <td>sanmartin</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>Female</td>\n",
       "      <td>1992-12-18</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7214 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                 name      first         last  \\\n",
       "0         1     miguel hernandez     miguel    hernandez   \n",
       "1         3          kevon dixon      kevon        dixon   \n",
       "2         4             ed philo         ed        philo   \n",
       "3         5          marcu brown      marcu        brown   \n",
       "4         6   bouthy pierrelouis     bouthy  pierrelouis   \n",
       "...     ...                  ...        ...          ...   \n",
       "7209  10996        steven butler     steven       butler   \n",
       "7210  10997      malcolm simmons    malcolm      simmons   \n",
       "7211  10999      winston gregory    winston      gregory   \n",
       "7212  11000          farrah jean     farrah         jean   \n",
       "7213  11001  florencia sanmartin  florencia    sanmartin   \n",
       "\n",
       "     compas_screening_date     sex         dob  age          age_cat  \\\n",
       "0               2013-08-14    Male  1947-04-18   69  Greater than 45   \n",
       "1               2013-01-27    Male  1982-01-22   34          25 - 45   \n",
       "2               2013-04-14    Male  1991-05-14   24     Less than 25   \n",
       "3               2013-01-13    Male  1993-01-21   23     Less than 25   \n",
       "4               2013-03-26    Male  1973-01-22   43          25 - 45   \n",
       "...                    ...     ...         ...  ...              ...   \n",
       "7209            2013-11-23    Male  1992-07-17   23     Less than 25   \n",
       "7210            2014-02-01    Male  1993-03-25   23     Less than 25   \n",
       "7211            2014-01-14    Male  1958-10-01   57  Greater than 45   \n",
       "7212            2014-03-09  Female  1982-11-17   33          25 - 45   \n",
       "7213            2014-06-30  Female  1992-12-18   23     Less than 25   \n",
       "\n",
       "                  race  ...  v_decile_score  v_score_text  v_screening_date  \\\n",
       "0                Other  ...               1           Low        2013-08-14   \n",
       "1     African-American  ...               1           Low        2013-01-27   \n",
       "2     African-American  ...               3           Low        2013-04-14   \n",
       "3     African-American  ...               6        Medium        2013-01-13   \n",
       "4                Other  ...               1           Low        2013-03-26   \n",
       "...                ...  ...             ...           ...               ...   \n",
       "7209  African-American  ...               5        Medium        2013-11-23   \n",
       "7210  African-American  ...               5        Medium        2014-02-01   \n",
       "7211             Other  ...               1           Low        2014-01-14   \n",
       "7212  African-American  ...               2           Low        2014-03-09   \n",
       "7213          Hispanic  ...               4           Low        2014-06-30   \n",
       "\n",
       "      in_custody  out_custody  priors_count.1 start   end event two_year_recid  \n",
       "0     2014-07-07   2014-07-14               0     0   327     0              0  \n",
       "1     2013-01-26   2013-02-05               0     9   159     1              1  \n",
       "2     2013-06-16   2013-06-16               4     0    63     0              1  \n",
       "3            NaN          NaN               1     0  1174     0              0  \n",
       "4            NaN          NaN               2     0  1102     0              0  \n",
       "...          ...          ...             ...   ...   ...   ...            ...  \n",
       "7209  2013-11-22   2013-11-24               0     1   860     0              0  \n",
       "7210  2014-01-31   2014-02-02               0     1   790     0              0  \n",
       "7211  2014-01-13   2014-01-14               0     0   808     0              0  \n",
       "7212  2014-03-08   2014-03-09               3     0   754     0              0  \n",
       "7213  2015-03-15   2015-03-15               2     0   258     0              1  \n",
       "\n",
       "[7214 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compas = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "compas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da4cd333-89c5-4aec-8ee1-5ad305897309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Male\n",
       "1         Male\n",
       "2         Male\n",
       "5         Male\n",
       "6         Male\n",
       "         ...  \n",
       "7209      Male\n",
       "7210      Male\n",
       "7211      Male\n",
       "7212    Female\n",
       "7213    Female\n",
       "Name: sex, Length: 6172, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy the pre-processing steps from \"Loading Data\" found on: https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb\n",
    "compas = compas[(compas[\"days_b_screening_arrest\"] <= 30) & (compas[\"days_b_screening_arrest\"] >= -30)]\n",
    "\n",
    "# nr of rows match those in link\n",
    "compas[\"sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8bb0e8a-5f2a-4bff-b115-576fef103302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# separate labels\n",
    "compas_y = compas[\"two_year_recid\"]\n",
    "compas_X = compas.drop(\"two_year_recid\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158ce077-b10b-422a-816b-92bbcfb3a092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compas_y = compas_y.map({0:1, 1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a51e42b2-99a5-41b0-a695-051a89a387cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compas_X = compas_X[[\"age\", \"c_charge_degree\", \"age_cat\", \"score_text\", \"sex\", \"priors_count\", \n",
    "                    \"days_b_screening_arrest\", \"decile_score\", \"race\", \"in_custody\", \"out_custody\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b5bf93-d27f-4a94-b319-d75dea19ad75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert dates to just years and numerical types\n",
    "def date_to_justyear(date):\n",
    "    if type(date) == str:\n",
    "        return int(date[:4])\n",
    "    \n",
    "    return date\n",
    "\n",
    "for column in [\"in_custody\", \"out_custody\"]:\n",
    "    compas_X[column] = compas_X[column].apply(func=date_to_justyear, convert_dtype=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5e4cd06-49d5-4c96-8522-493fea907b56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# separate sensitive attributes\n",
    "compas_sex = compas_X[\"sex\"]\n",
    "compas_race = compas_X[\"race\"]\n",
    "compas_age = compas_X[\"age\"]\n",
    "compas_age_cat = compas_X[\"age_cat\"]\n",
    "compas_X = compas_X.drop([\"race\", \"sex\", \"age\", \"age_cat\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79894f87-4a9d-4b9b-a8a8-5585b631c21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compas_race = compas_race.map({\"Caucasian\": \"White\", \"African-American\": \"Non_White\", \"Hispanic\": \"Non_White\", \"Other\": \"Non_White\", \"Asian\": \"Non_White\", \"Native American\": \"Non_White\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7a47cb8-d233-4fe9-83f1-849879c5751d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Male-Non_White\n",
       "1         Male-Non_White\n",
       "2         Male-Non_White\n",
       "5         Male-Non_White\n",
       "6             Male-White\n",
       "              ...       \n",
       "7209      Male-Non_White\n",
       "7210      Male-Non_White\n",
       "7211      Male-Non_White\n",
       "7212    Female-Non_White\n",
       "7213    Female-Non_White\n",
       "Length: 6172, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compas_sexrace = pd.concat([compas_sex, compas_race], axis=1)\n",
    "compas_sex_race = compas_sexrace[['sex', 'race']].agg('-'.join, axis=1)\n",
    "compas_sex_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf4285ca-d954-4310-a038-00008c19bf74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/97vsb8ys2xsd5zzsdl4ndt6c0000gn/T/ipykernel_54173/1967445180.py:2: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  compas_X = compas_X.fillna(compas_X.median())\n"
     ]
    }
   ],
   "source": [
    "# impute the numerical missing values with the median\n",
    "compas_X = compas_X.fillna(compas_X.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6609b761-9ce0-4baa-b843-018178d86e41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>in_custody_2003</th>\n",
       "      <th>in_custody_2009</th>\n",
       "      <th>in_custody_2013</th>\n",
       "      <th>in_custody_2014</th>\n",
       "      <th>in_custody_2015</th>\n",
       "      <th>in_custody_2016</th>\n",
       "      <th>out_custody_2013</th>\n",
       "      <th>out_custody_2014</th>\n",
       "      <th>out_custody_2015</th>\n",
       "      <th>out_custody_2016</th>\n",
       "      <th>out_custody_2020</th>\n",
       "      <th>c_charge_degree_F</th>\n",
       "      <th>c_charge_degree_M</th>\n",
       "      <th>score_text_High</th>\n",
       "      <th>score_text_Low</th>\n",
       "      <th>score_text_Medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6172 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      priors_count  days_b_screening_arrest  decile_score  in_custody_2003  \\\n",
       "0                0                     -1.0             1                0   \n",
       "1                0                     -1.0             3                0   \n",
       "2                4                     -1.0             4                0   \n",
       "5                0                      0.0             1                0   \n",
       "6               14                     -1.0             6                0   \n",
       "...            ...                      ...           ...              ...   \n",
       "7209             0                     -1.0             7                0   \n",
       "7210             0                     -1.0             3                0   \n",
       "7211             0                     -1.0             1                0   \n",
       "7212             3                     -1.0             2                0   \n",
       "7213             2                     -2.0             4                0   \n",
       "\n",
       "      in_custody_2009  in_custody_2013  in_custody_2014  in_custody_2015  \\\n",
       "0                   0                0                1                0   \n",
       "1                   0                1                0                0   \n",
       "2                   0                1                0                0   \n",
       "5                   0                1                0                0   \n",
       "6                   0                0                1                0   \n",
       "...               ...              ...              ...              ...   \n",
       "7209                0                1                0                0   \n",
       "7210                0                0                1                0   \n",
       "7211                0                0                1                0   \n",
       "7212                0                0                1                0   \n",
       "7213                0                0                0                1   \n",
       "\n",
       "      in_custody_2016  out_custody_2013  out_custody_2014  out_custody_2015  \\\n",
       "0                   0                 0                 1                 0   \n",
       "1                   0                 1                 0                 0   \n",
       "2                   0                 1                 0                 0   \n",
       "5                   0                 1                 0                 0   \n",
       "6                   0                 0                 1                 0   \n",
       "...               ...               ...               ...               ...   \n",
       "7209                0                 1                 0                 0   \n",
       "7210                0                 0                 1                 0   \n",
       "7211                0                 0                 1                 0   \n",
       "7212                0                 0                 1                 0   \n",
       "7213                0                 0                 0                 1   \n",
       "\n",
       "      out_custody_2016  out_custody_2020  c_charge_degree_F  \\\n",
       "0                    0                 0                  1   \n",
       "1                    0                 0                  1   \n",
       "2                    0                 0                  1   \n",
       "5                    0                 0                  0   \n",
       "6                    0                 0                  1   \n",
       "...                ...               ...                ...   \n",
       "7209                 0                 0                  1   \n",
       "7210                 0                 0                  1   \n",
       "7211                 0                 0                  1   \n",
       "7212                 0                 0                  0   \n",
       "7213                 0                 0                  1   \n",
       "\n",
       "      c_charge_degree_M  score_text_High  score_text_Low  score_text_Medium  \n",
       "0                     0                0               1                  0  \n",
       "1                     0                0               1                  0  \n",
       "2                     0                0               1                  0  \n",
       "5                     1                0               1                  0  \n",
       "6                     0                0               0                  1  \n",
       "...                 ...              ...             ...                ...  \n",
       "7209                  0                0               0                  1  \n",
       "7210                  0                0               1                  0  \n",
       "7211                  0                0               1                  0  \n",
       "7212                  1                0               1                  0  \n",
       "7213                  0                0               1                  0  \n",
       "\n",
       "[6172 rows x 19 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to one-hot-encoding\n",
    "compas_cat_X = pd.get_dummies(compas_X, columns=[\"in_custody\", \"out_custody\", \"c_charge_degree\", \"score_text\"])\n",
    "compas_cat_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b33edc1b-9093-4059-b422-fd7d60e99b44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a train and test split with same proportional size as Adult dataset\n",
    "compas_train_cat_X, compas_test_cat_X, compas_train_y, compas_test_y= train_test_split(compas_cat_X, compas_y, test_size=1/3, random_state=42)\n",
    "\n",
    "# also for the sensitive attributes with same random_state\n",
    "compas_train_sex, compas_test_sex, compas_train_y, compas_test_y = train_test_split(compas_sex, compas_y, test_size=1/3, random_state=42)\n",
    "compas_train_race, compas_test_race, compas_train_y, compas_test_y = train_test_split(compas_race, compas_y, test_size=1/3, random_state=42)\n",
    "compas_train_age, compas_test_age, compas_train_y, compas_test_y = train_test_split(compas_age, compas_y, test_size=1/3, random_state=42)\n",
    "compas_train_sex_race, compas_test_sex_race, compas_train_y, compas_test_y = train_test_split(compas_sex_race, compas_y, test_size=1/3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05712f2f-0e91-48c1-b985-d6d2a3ea4395",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reindex all datasets, drop=True to prevent addition of \"index\" column\n",
    "compas_train_cat_X = compas_train_cat_X.reset_index(drop=True)\n",
    "compas_train_y = compas_train_y.reset_index(drop=True)\n",
    "compas_train_sex = compas_train_sex.reset_index(drop=True)\n",
    "compas_train_race = compas_train_race.reset_index(drop=True)\n",
    "compas_train_sex_race = compas_train_sex_race.reset_index(drop=True)\n",
    "compas_train_age = compas_train_age.reset_index(drop=True)\n",
    "\n",
    "compas_test_cat_X = compas_test_cat_X.reset_index(drop=True)\n",
    "compas_test_y = compas_test_y.reset_index(drop=True)\n",
    "compas_test_sex = compas_test_sex.reset_index(drop=True)\n",
    "compas_test_race = compas_test_race.reset_index(drop=True)\n",
    "compas_test_sex_race = compas_test_sex_race.reset_index(drop=True)\n",
    "compas_test_age = compas_test_age.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1dd54d-b415-4f8b-88d8-ce274fe30b8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PAFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09b4d259-5c3b-4735-9c9d-0a6f1a41ad4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def oracle(dataset, sens_dataset, rule, s_i, mechanism=None, epsilon=0.05, delta=0.001):\n",
    "    \"\"\"Returns some (differentially privatised) statistics on the sensitive attribute for the specified dataframe and rule\n",
    "    \n",
    "    Args:\n",
    "        df: The DataFrame that the developers own, which does not contain sensitive attributes.\n",
    "            Used to calculate total quantities in (root) nodes.\n",
    "        sens_dataset: A Series that the developers do not own, which contains the sensitive attributes. \n",
    "            Combined sensitive attributes should be encoded as a Series, e.g. Black-Female\n",
    "        rule: The rule, as a string, for which the to estimate the sensitive attribute.\n",
    "        s_i: The sensitive attribute, its name comes from the ith element in the set S of sensitive attributes.\n",
    "            s_i should be in sens_dataset and should thus be a string. \n",
    "        mechanism: The privacy mechanism used on the returned counts. Can be one of \"gaussian\", \"laplacian\", \"exponential\", None. \n",
    "        epsilon: The privacy budget. Should be larger than 0.\n",
    "        delta: The privacy margin. Ignored when mechanism is either laplacian or gaussian. Should be in (0, 1]. \n",
    "        \n",
    "    Returns:\n",
    "        The number of times s_i occurs in sens_dataset, privatised via the mechanism. \n",
    "        \"\"\"\n",
    "        \n",
    "    # check epsilon and delta parameters\n",
    "    if epsilon <= 0 or (mechanism == \"gaussian\" and (delta <= 0 or delta > 1 or epsilon > 1)):\n",
    "        raise ValueError(\"The value of delta should be in (0,1] when using the gaussian mechanism\")\n",
    "    \n",
    "    if not sens_dataset.isin([s_i]).any():\n",
    "        raise KeyError(\"The requested sensitive attribute (s_i) is not in the sensitive dataframe (sens_dataset)\")\n",
    "        \n",
    "    # the answer if no privacy mechanism is applied\n",
    "    try:\n",
    "        no_mechanism = sens_dataset.loc[dataset[pd.eval(rule, engine='python')].index].value_counts(sort=False)[s_i]\n",
    "        \n",
    "    except KeyError:\n",
    "        no_mechanism = 0\n",
    "    \n",
    "    if mechanism == \"laplacian\":\n",
    "        # this is a histogram query so the l1-sensitivity = 1 as per Dwork & Roth \n",
    "        sensitivity = 1\n",
    "        return no_mechanism + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "    \n",
    "    elif mechanism == \"gaussian\":\n",
    "        # this is a histogram query so the l2-sensitivity = 2 as per Dwork & Roth\n",
    "        sensitivity = 2\n",
    "        return no_mechanism + np.random.normal(loc=0, scale=2 * sensitivity**2 * np.log(1.25 / delta) / epsilon**2)\n",
    "    \n",
    "    elif mechanism == \"exponential\":\n",
    "        # this query can only change by 1 if an instance is omitted so l1-sensitivity = 1\n",
    "        sensitivity = 1\n",
    "        \n",
    "        # np.arange is [start, stop) so + 1 for entire possible range\n",
    "        possible_values = np.arange(0, sens_dataset.loc[dataset[pd.eval(rule, engine='python')].index].value_counts().to_numpy().sum() + 1)\n",
    "        \n",
    "        # the utility is higher when the value is closer to the actual value\n",
    "        utility_scores = np.array([no_mechanism - abs(no_mechanism - value) for value in possible_values]) / 100\n",
    "        probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in utility_scores]\n",
    "        \n",
    "        # normalize probabilties to sum to 1\n",
    "        probabilities /= np.linalg.norm(probabilities, ord=1)\n",
    "        return np.random.choice(possible_values, p=probabilities)\n",
    "\n",
    "    # if no mechanism is given, return the unprivatised cocunt\n",
    "    return no_mechanism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "505f2212-a1d9-44b4-9cc5-49815eb5756c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def statistical_parity(y_pred, sens_dataset):\n",
    "    \"\"\"Calculates Statistical Parity Ratio using the predictions and the actual sensitive feature values\n",
    "    \n",
    "    Args:\n",
    "        y_pred: The predictions, should be of same size as sens_dataset.\n",
    "        sens_dataset: The Series with the sensitive attributes.\n",
    "        \n",
    "    Returns:\n",
    "        The true statistical parity ratio.\n",
    "        \"\"\"\n",
    "    accept_rates = []\n",
    "    \n",
    "    for sens_attr in sorted(sens_dataset.unique()):\n",
    "        accept_rates.append(np.sum((sens_dataset == sens_attr) & y_pred) / np.sum(sens_dataset == sens_attr))\n",
    "        \n",
    "    return min(accept_rates) / max(accept_rates)\n",
    "\n",
    "\n",
    "def estimate_sp(pos_ruleset, dataset, sens_dataset, S, mechanism, epsilon, delta=0.001):\n",
    "    \"\"\"Returns the estimated Statistical Parity of a tree for a privacy mechanism\n",
    "    \n",
    "    Args:\n",
    "        pos_ruleset: A list of rules that classify favorably in the tree. This is the representation of the\n",
    "        (relevant parts of the) tree. \n",
    "        dataset: The DataFrame that the developers own that does not contain sensitive feature values.\n",
    "        sens_dataset: The Series that contains the sensitive features, which the developers do not own.\n",
    "        S: The set/list of sensitive attributes, should all be in the sens_dataset attribute.\n",
    "        mechanism: The mechanism with which to privatise the queries. \n",
    "        epsilon: The privacy budget for the privacy mechanism. Should be larger than 0.\n",
    "        delta: The privacy margin. Ignored when mechanism is either laplacian or gaussian. Should be in (0, 1].\n",
    "        \n",
    "    Returns:\n",
    "        The statistical parity ratio for the specified pos_ruleset. \n",
    "        \"\"\"\n",
    "    \n",
    "    poscounts_per_si = np.zeros(len(S))\n",
    "    \n",
    "    # the variable name of the current dataset is inferred from the ruleset\n",
    "    datasetname = str(pos_ruleset[0].split('[')[0])[1:]\n",
    "    \n",
    "    # the base rule is a rule that includes all individuals, i.e. the condition is a tautology\n",
    "    # in this case we select all rows that have a value that is in the set of possible values of the first column\n",
    "    base_rule = f\"({datasetname}[{datasetname}.columns[0]].isin({datasetname}[{datasetname}.columns[0]].unique()))\"\n",
    "    \n",
    "    # query the size of each sensitive attribute in the dataset\n",
    "    total_per_si = [oracle(dataset, sens_dataset, base_rule, s_i, mechanism, 0.5 * epsilon, delta) for s_i in S]\n",
    "    \n",
    "    # replace each invalid value with balanced totals\n",
    "    for i, tot in enumerate(total_per_si):\n",
    "        if tot < 0 or tot > len(sens_dataset):\n",
    "            total_per_si[i] = (1 / len(S)) * len(sens_dataset)\n",
    "        \n",
    "    total_per_si = np.array(total_per_si)\n",
    "    \n",
    "    for rule in pos_ruleset:\n",
    "        # for each rule we find the distribution of sensitive attributes\n",
    "        rule_counts = np.zeros(len(S))\n",
    "        rule_total = len(sens_dataset[pd.eval(rule)])\n",
    "        \n",
    "        for i, s_i in enumerate(S):\n",
    "            # because the queries are disjoint, epsilon remains equal across queries\n",
    "            answer = round(oracle(dataset, sens_dataset, rule, s_i, mechanism, 0.5 * epsilon, delta))\n",
    "\n",
    "            # if invalid answers from query: replace with balanced node value\n",
    "            if answer < 0 or answer > len(sens_dataset):\n",
    "                answer = (1 / len(S)) * rule_total\n",
    "\n",
    "            rule_counts[i] += answer\n",
    "        \n",
    "        # the distribution for the current rule is added to the total\n",
    "        poscounts_per_si += rule_counts\n",
    "    \n",
    "    # calculate and return sp\n",
    "    accept_rates = poscounts_per_si / total_per_si\n",
    "    return np.min(accept_rates) / np.max(accept_rates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668f072-f760-406d-a3d0-0fdcde2d79a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tree construction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90083c98-2fb7-456b-a821-bbd2989f4410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 540 candidates, totalling 1620 fits\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "parameter_grid={\"criterion\":[\"entropy\", \"gini\"], \n",
    "                \"max_features\":[\"sqrt\", None, \"log2\"], \"ccp_alpha\": [0.01, 0.05, 0.1],\n",
    "               \"min_impurity_decrease\": [0.001, 0.005, 0.01, 0.025, 0.05], \n",
    "                \"min_samples_leaf\":[0.01, 0.02, 0.025, 0.05, 0.075, 0.1]}\n",
    "\n",
    "tree_cv = GridSearchCV(tree, param_grid=parameter_grid, scoring='balanced_accuracy', n_jobs=2, cv=3, verbose=1)\n",
    "tree_cv.fit(compas_train_cat_X, compas_train_y)\n",
    "best_tree = tree_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0add21e-b17c-4a01-aabb-2ed9048cee31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: array([0, 1, 2], dtype=int64),\n",
       " 3: array([0, 1, 3], dtype=int64),\n",
       " 6: array([0, 4, 5, 6], dtype=int64),\n",
       " 7: array([0, 4, 5, 7], dtype=int64),\n",
       " 8: array([0, 4, 8], dtype=int64)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_paths(tree, dataset):\n",
    "    def find_path(node_numb, path, x):\n",
    "        path.append(node_numb)\n",
    "        if node_numb == x:\n",
    "            return True\n",
    "        left = False\n",
    "        right = False\n",
    "        if (tree.tree_.children_left[node_numb] !=-1):\n",
    "            left = find_path(tree.tree_.children_left[node_numb], path, x)\n",
    "        if (tree.tree_.children_right[node_numb] !=-1):\n",
    "            right = find_path(tree.tree_.children_right[node_numb], path, x)\n",
    "        if left or right:\n",
    "            return True\n",
    "        path.remove(node_numb)\n",
    "        return False\n",
    "\n",
    "    # Leaves\n",
    "    leave_id = tree.apply(dataset)\n",
    "\n",
    "    paths = {}\n",
    "    for leaf in np.unique(leave_id):\n",
    "        path_leaf = []\n",
    "        find_path(0, path_leaf, leaf)\n",
    "        paths[leaf] = np.unique(np.sort(path_leaf))\n",
    "        \n",
    "    return paths\n",
    "        \n",
    "def avg_feature_thresholds(tree, dataset, max_depth=7):\n",
    "    paths = find_paths(tree, dataset)\n",
    "    feature_clause_thresholds = np.zeros((dataset.shape[1], max_depth))\n",
    "    feature_clause_counts = np.zeros((dataset.shape[1], max_depth))\n",
    "    seen_nodes = set()\n",
    "\n",
    "    for path in paths.values():\n",
    "        # last node is a leaf node that contains no feature\n",
    "        for depth, node in enumerate(path[:-1]):\n",
    "            if node not in seen_nodes:\n",
    "                feature_clause_thresholds[tree.tree_.feature[node], depth] += tree.tree_.threshold[node]\n",
    "                feature_clause_counts[tree.tree_.feature[node], depth] += 1\n",
    "                seen_nodes.add(node)\n",
    "    \n",
    "    return feature_clause_thresholds, feature_clause_counts\n",
    "\n",
    "find_paths(best_tree, compas_train_cat_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eed29bd-56bd-4c26-a127-32efb93c294b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_best_forest(n_trees=50, max_depth=7):\n",
    "    # Train a random forest classifier with n_estimators trees\n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=n_trees)\n",
    "    parameter_grid={\"criterion\":[\"entropy\", \"gini\"], \"max_depth\":np.arange(3,7+1), \n",
    "                    \"max_features\":[\"sqrt\", None], \n",
    "                    \"min_samples_leaf\":[0.01, 0.025, 0.05, 0.075, 0.1], \n",
    "                    \"ccp_alpha\": np.logspace(-5, 0, 5)[:-1]}\n",
    "\n",
    "    rf_cv = GridSearchCV(rf, param_grid=parameter_grid, scoring='balanced_accuracy', n_jobs=3, cv=3, verbose=1)\n",
    "    rf_cv.fit(compas_train_cat_X.values, compas_train_y)\n",
    "    return rf_cv.best_estimator_\n",
    "    \n",
    "def round_half(num):\n",
    "    return round(num * 2) / 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6be36f96-411f-4a80-bdac-59e093a718c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florianvandersteen/miniconda3/envs/experiments/lib/python3.11/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/florianvandersteen/miniconda3/envs/experiments/lib/python3.11/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/florianvandersteen/miniconda3/envs/experiments/lib/python3.11/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/florianvandersteen/miniconda3/envs/experiments/lib/python3.11/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/florianvandersteen/miniconda3/envs/experiments/lib/python3.11/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# transform the most useful numerical features to categorical features using binning\n",
    "n_trees = 5\n",
    "max_depth = 7\n",
    "numeric_feature_idxs = [0,1,2,3]\n",
    "best_rf = find_best_forest(n_trees=n_trees, max_depth=max_depth)\n",
    "\n",
    "# calculate average over all trees\n",
    "feature_clause_thresholds = np.zeros((compas_train_cat_X.shape[1], max_depth))\n",
    "feature_clause_counts = np.zeros((compas_train_cat_X.shape[1], max_depth)) \n",
    "for tree in best_rf.estimators_:\n",
    "    t, c = avg_feature_thresholds(tree, compas_train_cat_X, max_depth=max_depth)\n",
    "    feature_clause_thresholds += t\n",
    "    feature_clause_counts += c \n",
    "\n",
    "# categorize the numeric variables\n",
    "useful_feature_idxs = []\n",
    "for numeric_feature_idx in numeric_feature_idxs:\n",
    "    thresholds, counts = feature_clause_thresholds[numeric_feature_idx], feature_clause_counts[numeric_feature_idx]\n",
    "\n",
    "    if counts.any():\n",
    "        # ignore division by zero and zero / zero warnings\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            avgs = (thresholds/counts)\n",
    "\n",
    "        bins = [-np.inf] + sorted(np.unique([round(avg) for avg in avgs[~np.isnan(avgs)]])) + [np.inf] \n",
    "        names = [f'<{bins[1]}'] + [f'{binn}-{bins[i+2]}' for i, binn in enumerate(bins[1:-2])] + [f'{bins[-2]}+']\n",
    "\n",
    "        compas_train_cat_X.iloc[:, numeric_feature_idx] = pd.cut(compas_train_cat_X.iloc[:, numeric_feature_idx], bins, labels=names)\n",
    "        compas_test_cat_X.iloc[:, numeric_feature_idx] = pd.cut(compas_test_cat_X.iloc[:, numeric_feature_idx], bins, labels=names)\n",
    "        useful_feature_idxs.append(numeric_feature_idx)\n",
    "\n",
    "compas_train_cat_X = pd.get_dummies(data=compas_train_cat_X, columns=compas_train_cat_X.columns[useful_feature_idxs])\n",
    "compas_test_cat_X = pd.get_dummies(data=compas_test_cat_X, columns=compas_test_cat_X.columns[useful_feature_idxs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e314f1d-ffa3-4faa-9ce7-7ed76e035451",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_custody_2003</th>\n",
       "      <th>in_custody_2009</th>\n",
       "      <th>in_custody_2013</th>\n",
       "      <th>in_custody_2014</th>\n",
       "      <th>in_custody_2015</th>\n",
       "      <th>in_custody_2016</th>\n",
       "      <th>out_custody_2013</th>\n",
       "      <th>out_custody_2014</th>\n",
       "      <th>out_custody_2015</th>\n",
       "      <th>out_custody_2016</th>\n",
       "      <th>...</th>\n",
       "      <th>priors_count_0-1</th>\n",
       "      <th>priors_count_1-2</th>\n",
       "      <th>priors_count_2-6</th>\n",
       "      <th>priors_count_6+</th>\n",
       "      <th>days_b_screening_arrest_&lt;-1</th>\n",
       "      <th>days_b_screening_arrest_-1-0</th>\n",
       "      <th>days_b_screening_arrest_0+</th>\n",
       "      <th>decile_score_&lt;5</th>\n",
       "      <th>decile_score_5-6</th>\n",
       "      <th>decile_score_6+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2058 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      in_custody_2003  in_custody_2009  in_custody_2013  in_custody_2014  \\\n",
       "0                   0                0                0                1   \n",
       "1                   0                0                1                0   \n",
       "2                   0                0                0                0   \n",
       "3                   0                0                1                0   \n",
       "4                   0                0                1                0   \n",
       "...               ...              ...              ...              ...   \n",
       "2053                0                0                0                0   \n",
       "2054                0                0                1                0   \n",
       "2055                0                0                0                1   \n",
       "2056                0                0                1                0   \n",
       "2057                0                0                0                0   \n",
       "\n",
       "      in_custody_2015  in_custody_2016  out_custody_2013  out_custody_2014  \\\n",
       "0                   0                0                 0                 1   \n",
       "1                   0                0                 1                 0   \n",
       "2                   1                0                 0                 0   \n",
       "3                   0                0                 1                 0   \n",
       "4                   0                0                 1                 0   \n",
       "...               ...              ...               ...               ...   \n",
       "2053                1                0                 0                 0   \n",
       "2054                0                0                 1                 0   \n",
       "2055                0                0                 0                 0   \n",
       "2056                0                0                 1                 0   \n",
       "2057                0                1                 0                 0   \n",
       "\n",
       "      out_custody_2015  out_custody_2016  ...  priors_count_0-1  \\\n",
       "0                    0                 0  ...                 0   \n",
       "1                    0                 0  ...                 1   \n",
       "2                    1                 0  ...                 0   \n",
       "3                    0                 0  ...                 0   \n",
       "4                    0                 0  ...                 1   \n",
       "...                ...               ...  ...               ...   \n",
       "2053                 1                 0  ...                 0   \n",
       "2054                 0                 0  ...                 0   \n",
       "2055                 1                 0  ...                 0   \n",
       "2056                 0                 0  ...                 1   \n",
       "2057                 0                 1  ...                 0   \n",
       "\n",
       "      priors_count_1-2  priors_count_2-6  priors_count_6+  \\\n",
       "0                    0                 0                1   \n",
       "1                    0                 0                0   \n",
       "2                    1                 0                0   \n",
       "3                    0                 0                0   \n",
       "4                    0                 0                0   \n",
       "...                ...               ...              ...   \n",
       "2053                 0                 1                0   \n",
       "2054                 0                 0                0   \n",
       "2055                 0                 1                0   \n",
       "2056                 0                 0                0   \n",
       "2057                 0                 1                0   \n",
       "\n",
       "      days_b_screening_arrest_<-1  days_b_screening_arrest_-1-0  \\\n",
       "0                               0                             1   \n",
       "1                               0                             1   \n",
       "2                               0                             1   \n",
       "3                               0                             1   \n",
       "4                               1                             0   \n",
       "...                           ...                           ...   \n",
       "2053                            1                             0   \n",
       "2054                            1                             0   \n",
       "2055                            1                             0   \n",
       "2056                            1                             0   \n",
       "2057                            1                             0   \n",
       "\n",
       "      days_b_screening_arrest_0+  decile_score_<5  decile_score_5-6  \\\n",
       "0                              0                0                 0   \n",
       "1                              0                1                 0   \n",
       "2                              0                1                 0   \n",
       "3                              0                1                 0   \n",
       "4                              0                1                 0   \n",
       "...                          ...              ...               ...   \n",
       "2053                           0                1                 0   \n",
       "2054                           0                1                 0   \n",
       "2055                           0                0                 0   \n",
       "2056                           0                1                 0   \n",
       "2057                           0                0                 0   \n",
       "\n",
       "      decile_score_6+  \n",
       "0                   1  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "2053                0  \n",
       "2054                0  \n",
       "2055                1  \n",
       "2056                0  \n",
       "2057                1  \n",
       "\n",
       "[2058 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compas_test_cat_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c8d289e-0527-4240-96f2-074cfb35eace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_best_tree(dataset, dataset_labels, minleaf=0.01):\n",
    "    # no random_state because we want a different tree each run\n",
    "    tree = DecisionTreeClassifier()\n",
    "\n",
    "    parameter_grid = {\"criterion\":[\"entropy\", \"gini\"],\n",
    "                      \"max_features\":[\"sqrt\", \"log2\"], \n",
    "                      \"min_samples_leaf\":[minleaf]}\n",
    "    \n",
    "    tree_cv = GridSearchCV(tree, param_grid=parameter_grid, scoring='balanced_accuracy', n_jobs=2, cv=3, verbose=0)\n",
    "    tree_cv.fit(dataset, dataset_labels)\n",
    "    best_tree = tree_cv.best_estimator_\n",
    "    return best_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "311e2661-0593-4cda-b3d3-6ec26b5be06a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# taken from: https://stackoverflow.com/a/51398390\n",
    "def is_leaf(inner_tree, index):\n",
    "    # check whether node is leaf node\n",
    "    return (inner_tree.children_left[index] == TREE_LEAF and \n",
    "            inner_tree.children_right[index] == TREE_LEAF)\n",
    "\n",
    "def prune_index(inner_tree, decisions, index=0):\n",
    "    # start pruning from the bottom - if we start from the top, we might miss\n",
    "    # nodes that become leaves during pruning\n",
    "    if not is_leaf(inner_tree, inner_tree.children_left[index]):\n",
    "        prune_index(inner_tree, decisions, inner_tree.children_left[index])\n",
    "    if not is_leaf(inner_tree, inner_tree.children_right[index]):\n",
    "        prune_index(inner_tree, decisions, inner_tree.children_right[index])\n",
    "\n",
    "    # prune children if both children are leaves now and make the same decision\n",
    "    if (is_leaf(inner_tree, inner_tree.children_left[index]) and\n",
    "        is_leaf(inner_tree, inner_tree.children_right[index]) and\n",
    "        (decisions[index] == decisions[inner_tree.children_left[index]]) and \n",
    "        (decisions[index] == decisions[inner_tree.children_right[index]])):\n",
    "        # turn node into a leaf by \"unlinking\" its children\n",
    "        inner_tree.children_left[index] = TREE_LEAF\n",
    "        inner_tree.children_right[index] = TREE_LEAF\n",
    "\n",
    "def prune_duplicate_leaves(mdl):\n",
    "    # Remove leaves if all siblings make the same decision\n",
    "    decisions = mdl.tree_.value.argmax(axis=2).flatten().tolist() # Decision for each node\n",
    "    prune_index(mdl.tree_, decisions)\n",
    "    \n",
    "# pruning happens in-place\n",
    "prune_duplicate_leaves(best_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0aa8b8ba-acea-4432-a13e-02e0f4f38994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def positive_rules (tree, rules):\n",
    "    \"\"\"From the extracted rules, return those that have a favorable classification\n",
    "\n",
    "    Arg:\n",
    "        tree: The tree classification object from which the rules are extracted. \n",
    "        rules: Dict of which the values are rule strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of all the rules that classify favorably\"\"\"\n",
    "\n",
    "    # only those rules are added for which the majority of individuals in the node is at index 1, i.e. max\n",
    "    # index 1 corresponds to class 1\n",
    "    return [rule for node_id, rule in rules.items() if np.argmax(tree.tree_.value[node_id][0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af57931f-a5db-4172-859d-42fae59a22ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# taken from: https://stackoverflow.com/a/56427596\n",
    "def extract_pos_rules(tree, dataset, datasetname):\n",
    "    n_nodes = tree.tree_.node_count\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    feature = tree.tree_.feature\n",
    "    threshold = tree.tree_.threshold\n",
    "\n",
    "    def find_path(node_numb, path, x):\n",
    "        path.append(node_numb)\n",
    "        if node_numb == x:\n",
    "            return True\n",
    "        left = False\n",
    "        right = False\n",
    "        if (children_left[node_numb] !=-1):\n",
    "            left = find_path(children_left[node_numb], path, x)\n",
    "        if (children_right[node_numb] !=-1):\n",
    "            right = find_path(children_right[node_numb], path, x)\n",
    "        if left or right :\n",
    "            return True\n",
    "        path.remove(node_numb)\n",
    "        return False\n",
    "\n",
    "\n",
    "    def get_rule(datasetname, path, column_names):\n",
    "        mask = '('\n",
    "        for index, node in enumerate(path):\n",
    "            # check if we are not in the leaf\n",
    "            if index!=len(path)-1:\n",
    "                # under or over the threshold?\n",
    "                if (children_left[node] == path[index+1]):\n",
    "                    mask += f\"{datasetname}['{column_names[feature[node]]}']<= {threshold[node]}\\t \"\n",
    "                else:\n",
    "                    mask += f\"{datasetname}['{column_names[feature[node]]}']> {threshold[node]} \\t \"\n",
    "\n",
    "        # insert the & at the right places\n",
    "        mask = mask.replace(\"\\t\", \"&\", mask.count(\"\\t\") - 1)\n",
    "        mask = mask.replace(\"\\t\", \"\")\n",
    "        mask += \")\"\n",
    "        return mask\n",
    "    \n",
    "    # Leaves\n",
    "    leave_id = tree.apply(dataset)\n",
    "\n",
    "    paths = {}\n",
    "    for leaf in np.unique(leave_id):\n",
    "        path_leaf = []\n",
    "        find_path(0, path_leaf, leaf)\n",
    "        paths[leaf] = np.unique(np.sort(path_leaf))\n",
    "\n",
    "    rules = {}\n",
    "    for key in paths:\n",
    "        rules[key] = get_rule(datasetname, paths[key], [name for name in dataset.columns])\n",
    "        \n",
    "    return positive_rules(tree, rules)\n",
    "        \n",
    "# extract_pos_rules(best_tree, compas_train_cat_X, \"compas_train_cat_X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e6cb6-a3eb-4213-a9a2-9ac977ce6449",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87064d71-b130-4e39-8a2e-417dc8838437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bootstrap(dataset, dataset_labels, sens_dataset):\n",
    "    indices = np.random.choice(dataset.index, size=len(dataset.index))\n",
    "    \n",
    "    return dataset.iloc[indices], dataset_labels.iloc[indices], sens_dataset.iloc[indices]\n",
    "\n",
    "# dataset, labels, sens_dataset = bootstrap(adult_test_cat_X, adult_test_y, adult_test_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4122c8a-e29b-425d-94d1-7ce76285a373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def experiment(trainset, sens_trainset, trainsetname, trainset_labels, testset, sens_testset, testsetname, \n",
    "               testset_labels, epsilon=0.1, minleaf=0.01, runs=5, combined=False):\n",
    "    tree_sps = np.zeros(runs)\n",
    "    estimated_sps = np.zeros(runs)\n",
    "    for i in range(runs):\n",
    "        ruleset = []\n",
    "        while ruleset == [] or ruleset == ['()']:\n",
    "            # sample with replacement\n",
    "            dataset, dataset_labels, sens_dataset = bootstrap(trainset, trainset_labels, sens_trainset)\n",
    "            \n",
    "            # build tree \n",
    "            best_tree = find_best_tree(trainset, trainset_labels, minleaf)\n",
    "        \n",
    "            # extract positive rules\n",
    "            prune_duplicate_leaves(best_tree)\n",
    "            ruleset = extract_pos_rules(best_tree, trainset, testsetname)\n",
    "        \n",
    "        if combined:\n",
    "            ruleset = [\" | \".join(rule for rule in ruleset)]\n",
    "\n",
    "        # calculate true sp\n",
    "        tree_sps[i] = statistical_parity(best_tree.predict(testset), sens_testset)\n",
    "        \n",
    "        # apply PAFER\n",
    "        estimated_sps[i] = estimate_sp(ruleset, testset, sens_testset, sorted(sens_testset.unique()), mechanism='laplacian', epsilon=epsilon)\n",
    "        \n",
    "    return tree_sps, estimated_sps\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9a288ef-b77a-42e8-934c-ca5ebc537432",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2        0.19748101 0.19496203 0.19244304 0.18992405 0.18740506\n",
      " 0.18488608 0.18236709 0.1798481  0.17732911 0.17481013 0.17229114\n",
      " 0.16977215 0.16725316 0.16473418 0.16221519 0.1596962  0.15717722\n",
      " 0.15465823 0.15213924 0.14962025 0.14710127 0.14458228 0.14206329\n",
      " 0.1395443  0.13702532 0.13450633 0.13198734 0.12946835 0.12694937\n",
      " 0.12443038 0.12191139 0.11939241 0.11687342 0.11435443 0.11183544\n",
      " 0.10931646 0.10679747 0.10427848 0.10175949 0.09924051 0.09672152\n",
      " 0.09420253 0.09168354 0.08916456 0.08664557 0.08412658 0.08160759\n",
      " 0.07908861 0.07656962 0.07405063 0.07153165 0.06901266 0.06649367\n",
      " 0.06397468 0.0614557  0.05893671 0.05641772 0.05389873 0.05137975\n",
      " 0.04886076 0.04634177 0.04382278 0.0413038  0.03878481 0.03626582\n",
      " 0.03374684 0.03122785 0.02870886 0.02618987 0.02367089 0.0211519\n",
      " 0.01863291 0.01611392 0.01359494 0.01107595 0.00855696 0.00603797\n",
      " 0.00351899 0.001     ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 80/80 [09:44<00:00,  7.30s/it]\n"
     ]
    }
   ],
   "source": [
    "minleafs = np.linspace(0.2, 0.001, 80)\n",
    "print(minleafs)\n",
    "runs = 3\n",
    "epsilon = 0.1\n",
    "\n",
    "# storage for results\n",
    "avg_tree_sps = []\n",
    "avg_estimated_sps = []\n",
    "avg_errs = []\n",
    "uncerts = []\n",
    "eighty_percents = []\n",
    "for minleaf in tqdm(minleafs):\n",
    "    tree_sps, estimated_sps = experiment(compas_train_cat_X, compas_train_sex, \"compas_train_cat_X\", compas_train_y, \n",
    "                                         compas_test_cat_X, compas_test_sex, \"compas_test_cat_X\", compas_test_y,\n",
    "                                         epsilon=epsilon, minleaf=minleaf, runs=runs)\n",
    "    \n",
    "    avg_tree_sps.append(np.mean(tree_sps))\n",
    "    avg_estimated_sps.append(np.mean(estimated_sps))\n",
    "    avg_errs.append(np.mean(np.abs(tree_sps - estimated_sps)))\n",
    "    uncerts.append(np.std(np.abs(tree_sps - estimated_sps)) / np.sqrt(len(tree_sps)))\n",
    "    eighty_percents.append((tree_sps >= 0.8))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f40470ef-af86-44f9-af0e-1a8563fd71cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_tree_sps = np.array(avg_tree_sps)\n",
    "avg_estimated_sps = np.array(avg_estimated_sps)\n",
    "avg_errs = np.array(avg_errs)\n",
    "uncerts = np.array(uncerts)\n",
    "eighty_percents = np.array(eighty_percents)\n",
    "\n",
    "for arr, name in zip([avg_tree_sps, avg_estimated_sps, avg_errs, uncerts, eighty_percents], [\"tree_sps\", \"estimated_sps\", \"errs\", \"uncerts\", \"eighty_percents\"]):\n",
    "    with open(f\"compas-sex-{name}\", \"wb\") as f:\n",
    "        np.save(f, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b1fcac5-0597-4db7-bcbe-a10edbbc7f54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2        0.19748101 0.19496203 0.19244304 0.18992405 0.18740506\n",
      " 0.18488608 0.18236709 0.1798481  0.17732911 0.17481013 0.17229114\n",
      " 0.16977215 0.16725316 0.16473418 0.16221519 0.1596962  0.15717722\n",
      " 0.15465823 0.15213924 0.14962025 0.14710127 0.14458228 0.14206329\n",
      " 0.1395443  0.13702532 0.13450633 0.13198734 0.12946835 0.12694937\n",
      " 0.12443038 0.12191139 0.11939241 0.11687342 0.11435443 0.11183544\n",
      " 0.10931646 0.10679747 0.10427848 0.10175949 0.09924051 0.09672152\n",
      " 0.09420253 0.09168354 0.08916456 0.08664557 0.08412658 0.08160759\n",
      " 0.07908861 0.07656962 0.07405063 0.07153165 0.06901266 0.06649367\n",
      " 0.06397468 0.0614557  0.05893671 0.05641772 0.05389873 0.05137975\n",
      " 0.04886076 0.04634177 0.04382278 0.0413038  0.03878481 0.03626582\n",
      " 0.03374684 0.03122785 0.02870886 0.02618987 0.02367089 0.0211519\n",
      " 0.01863291 0.01611392 0.01359494 0.01107595 0.00855696 0.00603797\n",
      " 0.00351899 0.001     ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 80/80 [7:30:14<00:00, 337.68s/it]\n"
     ]
    }
   ],
   "source": [
    "minleafs = np.linspace(0.2, 0.001, 80)\n",
    "print(minleafs)\n",
    "runs = 50\n",
    "epsilon = 0.1\n",
    "\n",
    "# storage for results\n",
    "avg_tree_sps = []\n",
    "avg_estimated_sps = []\n",
    "avg_errs = []\n",
    "uncerts = []\n",
    "eighty_percents = []\n",
    "for minleaf in tqdm(minleafs):\n",
    "    tree_sps, estimated_sps = experiment(compas_train_cat_X, compas_train_race, \"compas_train_cat_X\", compas_train_y, \n",
    "                                         compas_test_cat_X, compas_test_race, \"compas_test_cat_X\", compas_test_y,\n",
    "                                         epsilon=epsilon, minleaf=minleaf, runs=runs)\n",
    "    \n",
    "    avg_tree_sps.append(np.mean(tree_sps))\n",
    "    avg_estimated_sps.append(np.mean(estimated_sps))\n",
    "    avg_errs.append(np.mean(np.abs(tree_sps - estimated_sps)))\n",
    "    uncerts.append(np.std(np.abs(tree_sps - estimated_sps)) / np.sqrt(len(tree_sps)))\n",
    "    eighty_percents.append((tree_sps >= 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18ea14-ac2c-4814-8be5-6687ec461dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_tree_sps = np.array(avg_tree_sps)\n",
    "avg_estimated_sps = np.array(avg_estimated_sps)\n",
    "avg_errs = np.array(avg_errs)\n",
    "uncerts = np.array(uncerts)\n",
    "eighty_percents = np.array(eighty_percents)\n",
    "\n",
    "for arr, name in zip([avg_tree_sps, avg_estimated_sps, avg_errs, uncerts, eighty_percents], [\"tree_sps\", \"estimated_sps\", \"errs\", \"uncerts\", \"eighty_percents\"]):\n",
    "    with open(f\"compas-race-{name}\", \"wb\") as f:\n",
    "        np.save(f, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc869888-922f-43a8-adf3-d51c2dd202e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minleafs = np.linspace(0.2, 0.001, 80)\n",
    "print(minleafs)\n",
    "runs = 50\n",
    "epsilon = 0.1\n",
    "\n",
    "# storage for results\n",
    "avg_tree_sps = []\n",
    "avg_estimated_sps = []\n",
    "avg_errs = []\n",
    "uncerts = []\n",
    "eighty_percents = []\n",
    "for minleaf in tqdm(minleafs):\n",
    "    tree_sps, estimated_sps = experiment(compas_train_cat_X, compas_train_sex_race, \"compas_train_cat_X\", compas_train_y, \n",
    "                                         compas_test_cat_X, compas_test_sex_race, \"compas_test_cat_X\", compas_test_y,\n",
    "                                         epsilon=epsilon, minleaf=minleaf, runs=runs)\n",
    "    \n",
    "    avg_tree_sps.append(np.mean(tree_sps))\n",
    "    avg_estimated_sps.append(np.mean(estimated_sps))\n",
    "    avg_errs.append(np.mean(np.abs(tree_sps - estimated_sps)))\n",
    "    uncerts.append(np.std(np.abs(tree_sps - estimated_sps)) / np.sqrt(len(tree_sps)))\n",
    "    eighty_percents.append((tree_sps >= 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26f3047f-a007-4081-a557-8762821490e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_tree_sps = np.array(avg_tree_sps)\n",
    "avg_estimated_sps = np.array(avg_estimated_sps)\n",
    "avg_errs = np.array(avg_errs)\n",
    "uncerts = np.array(uncerts)\n",
    "eighty_percents = np.array(eighty_percents)\n",
    "\n",
    "for arr, name in zip([avg_tree_sps, avg_estimated_sps, avg_errs, uncerts, eighty_percents], [\"tree_sps\", \"estimated_sps\", \"errs\", \"uncerts\", \"eighty_percents\"]):\n",
    "    with open(f\"compas-sex_race-{name}\", \"wb\") as f:\n",
    "        np.save(f, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893e628-f7ff-4903-88a2-6021efce1d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
